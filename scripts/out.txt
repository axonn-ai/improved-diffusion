Logging to /tmp/openai-2024-02-05-14-36-42-036617
creating model and diffusion...
Number of Model Parameters on Rank 0: 31912515
creating data loader...
training...
Number of Model Parameters on Rank 1: 31912515
------------------------
| grad_norm | 2.19     |
| loss      | 1.01     |
| loss_q0   | 1.04     |
| loss_q1   | 1        |
| loss_q2   | 0.997    |
| loss_q3   | 1.02     |
| mse       | 0.998    |
| mse_q0    | 1.01     |
| mse_q1    | 0.996    |
| mse_q2    | 0.992    |
| mse_q3    | 0.995    |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0156   |
| vb_q0     | 0.0297   |
| vb_q1     | 0.00479  |
| vb_q2     | 0.0048   |
| vb_q3     | 0.024    |
------------------------
------------------------
| grad_norm | 2.35     |
| loss      | 0.943    |
| loss_q0   | 0.978    |
| loss_q1   | 0.936    |
| loss_q2   | 0.912    |
| loss_q3   | 0.949    |
| mse       | 0.928    |
| mse_q0    | 0.959    |
| mse_q1    | 0.931    |
| mse_q2    | 0.908    |
| mse_q3    | 0.916    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0153   |
| vb_q0     | 0.0196   |
| vb_q1     | 0.00466  |
| vb_q2     | 0.00462  |
| vb_q3     | 0.0329   |
------------------------
------------------------
| grad_norm | 2.55     |
| loss      | 0.775    |
| loss_q0   | 0.849    |
| loss_q1   | 0.755    |
| loss_q2   | 0.733    |
| loss_q3   | 0.761    |
| mse       | 0.761    |
| mse_q0    | 0.829    |
| mse_q1    | 0.751    |
| mse_q2    | 0.73     |
| mse_q3    | 0.733    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.014    |
| vb_q0     | 0.0204   |
| vb_q1     | 0.00379  |
| vb_q2     | 0.00367  |
| vb_q3     | 0.0283   |
------------------------
------------------------
| grad_norm | 2.36     |
| loss      | 0.613    |
| loss_q0   | 0.703    |
| loss_q1   | 0.577    |
| loss_q2   | 0.575    |
| loss_q3   | 0.593    |
| mse       | 0.599    |
| mse_q0    | 0.681    |
| mse_q1    | 0.574    |
| mse_q2    | 0.573    |
| mse_q3    | 0.564    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0141   |
| vb_q0     | 0.0224   |
| vb_q1     | 0.00289  |
| vb_q2     | 0.00289  |
| vb_q3     | 0.0294   |
------------------------
------------------------
| grad_norm | 2.08     |
| loss      | 0.484    |
| loss_q0   | 0.597    |
| loss_q1   | 0.458    |
| loss_q2   | 0.438    |
| loss_q3   | 0.447    |
| mse       | 0.469    |
| mse_q0    | 0.555    |
| mse_q1    | 0.456    |
| mse_q2    | 0.436    |
| mse_q3    | 0.432    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.015    |
| vb_q0     | 0.0421   |
| vb_q1     | 0.0023   |
| vb_q2     | 0.00222  |
| vb_q3     | 0.0148   |
------------------------
------------------------
| grad_norm | 1.77     |
| loss      | 1.88     |
| loss_q0   | 0.484    |
| loss_q1   | 0.36     |
| loss_q2   | 0.337    |
| loss_q3   | 6.22     |
| mse       | 0.375    |
| mse_q0    | 0.469    |
| mse_q1    | 0.358    |
| mse_q2    | 0.336    |
| mse_q3    | 0.329    |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 1.51     |
| vb_q0     | 0.0144   |
| vb_q1     | 0.00181  |
| vb_q2     | 0.00173  |
| vb_q3     | 5.89     |
------------------------
------------------------
| grad_norm | 1.51     |
| loss      | 0.318    |
| loss_q0   | 0.432    |
| loss_q1   | 0.289    |
| loss_q2   | 0.263    |
| loss_q3   | 0.279    |
| mse       | 0.308    |
| mse_q0    | 0.418    |
| mse_q1    | 0.287    |
| mse_q2    | 0.262    |
| mse_q3    | 0.255    |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.01     |
| vb_q0     | 0.0134   |
| vb_q1     | 0.00146  |
| vb_q2     | 0.00133  |
| vb_q3     | 0.0235   |
------------------------
------------------------
| grad_norm | 1.31     |
| loss      | 0.261    |
| loss_q0   | 0.39     |
| loss_q1   | 0.236    |
| loss_q2   | 0.21     |
| loss_q3   | 0.213    |
| mse       | 0.252    |
| mse_q0    | 0.371    |
| mse_q1    | 0.234    |
| mse_q2    | 0.209    |
| mse_q3    | 0.199    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.00877  |
| vb_q0     | 0.0199   |
| vb_q1     | 0.00118  |
| vb_q2     | 0.00104  |
| vb_q3     | 0.0137   |
------------------------
------------------------
| grad_norm | 1.14     |
| loss      | 0.214    |
| loss_q0   | 0.345    |
| loss_q1   | 0.191    |
| loss_q2   | 0.165    |
| loss_q3   | 0.161    |
| mse       | 0.207    |
| mse_q0    | 0.324    |
| mse_q1    | 0.191    |
| mse_q2    | 0.164    |
| mse_q3    | 0.156    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00671  |
| vb_q0     | 0.0209   |
| vb_q1     | 0.000957 |
| vb_q2     | 0.000835 |
| vb_q3     | 0.00502  |
------------------------
------------------------
| grad_norm | 0.975    |
| loss      | 0.191    |
| loss_q0   | 0.322    |
| loss_q1   | 0.167    |
| loss_q2   | 0.134    |
| loss_q3   | 0.131    |
| mse       | 0.184    |
| mse_q0    | 0.305    |
| mse_q1    | 0.166    |
| mse_q2    | 0.134    |
| mse_q3    | 0.124    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00626  |
| vb_q0     | 0.017    |
| vb_q1     | 0.000835 |
| vb_q2     | 0.000669 |
| vb_q3     | 0.00677  |
------------------------
------------------------
| grad_norm | 0.853    |
| loss      | 0.169    |
| loss_q0   | 0.297    |
| loss_q1   | 0.144    |
| loss_q2   | 0.113    |
| loss_q3   | 0.105    |
| mse       | 0.166    |
| mse_q0    | 0.288    |
| mse_q1    | 0.143    |
| mse_q2    | 0.113    |
| mse_q3    | 0.102    |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.0035   |
| vb_q0     | 0.00879  |
| vb_q1     | 0.000725 |
| vb_q2     | 0.000574 |
| vb_q3     | 0.00304  |
------------------------
------------------------
| grad_norm | 0.763    |
| loss      | 0.166    |
| loss_q0   | 0.34     |
| loss_q1   | 0.131    |
| loss_q2   | 0.0986   |
| loss_q3   | 0.0904   |
| mse       | 0.153    |
| mse_q0    | 0.296    |
| mse_q1    | 0.131    |
| mse_q2    | 0.0981   |
| mse_q3    | 0.0847   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.0126   |
| vb_q0     | 0.0438   |
| vb_q1     | 0.000658 |
| vb_q2     | 0.000487 |
| vb_q3     | 0.00567  |
------------------------
------------------------
| grad_norm | 0.701    |
| loss      | 0.147    |
| loss_q0   | 0.32     |
| loss_q1   | 0.12     |
| loss_q2   | 0.0852   |
| loss_q3   | 0.0769   |
| mse       | 0.137    |
| mse_q0    | 0.283    |
| mse_q1    | 0.12     |
| mse_q2    | 0.0848   |
| mse_q3    | 0.0738   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.00956  |
| vb_q0     | 0.0376   |
| vb_q1     | 0.000612 |
| vb_q2     | 0.00043  |
| vb_q3     | 0.00306  |
------------------------
------------------------
| grad_norm | 0.643    |
| loss      | 0.134    |
| loss_q0   | 0.301    |
| loss_q1   | 0.108    |
| loss_q2   | 0.0782   |
| loss_q3   | 0.0653   |
| mse       | 0.128    |
| mse_q0    | 0.282    |
| mse_q1    | 0.107    |
| mse_q2    | 0.0778   |
| mse_q3    | 0.0632   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.0052   |
| vb_q0     | 0.0191   |
| vb_q1     | 0.000537 |
| vb_q2     | 0.000391 |
| vb_q3     | 0.00209  |
------------------------
------------------------
| grad_norm | 0.588    |
| loss      | 0.134    |
| loss_q0   | 0.296    |
| loss_q1   | 0.107    |
| loss_q2   | 0.0706   |
| loss_q3   | 0.0572   |
| mse       | 0.125    |
| mse_q0    | 0.266    |
| mse_q1    | 0.107    |
| mse_q2    | 0.0703   |
| mse_q3    | 0.0553   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.00849  |
| vb_q0     | 0.03     |
| vb_q1     | 0.000554 |
| vb_q2     | 0.000351 |
| vb_q3     | 0.00193  |
------------------------
------------------------
| grad_norm | 0.541    |
| loss      | 0.122    |
| loss_q0   | 0.281    |
| loss_q1   | 0.0996   |
| loss_q2   | 0.0663   |
| loss_q3   | 0.0525   |
| mse       | 0.117    |
| mse_q0    | 0.264    |
| mse_q1    | 0.0991   |
| mse_q2    | 0.0659   |
| mse_q3    | 0.0508   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.00481  |
| vb_q0     | 0.0173   |
| vb_q1     | 0.000502 |
| vb_q2     | 0.000333 |
| vb_q3     | 0.00175  |
------------------------
------------------------
| grad_norm | 0.509    |
| loss      | 0.12     |
| loss_q0   | 0.272    |
| loss_q1   | 0.0974   |
| loss_q2   | 0.062    |
| loss_q3   | 0.0488   |
| mse       | 0.115    |
| mse_q0    | 0.254    |
| mse_q1    | 0.0969   |
| mse_q2    | 0.0617   |
| mse_q3    | 0.0476   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.0048   |
| vb_q0     | 0.0174   |
| vb_q1     | 0.000494 |
| vb_q2     | 0.000305 |
| vb_q3     | 0.00123  |
------------------------
------------------------
| grad_norm | 0.512    |
| loss      | 0.113    |
| loss_q0   | 0.26     |
| loss_q1   | 0.0931   |
| loss_q2   | 0.0603   |
| loss_q3   | 0.0472   |
| mse       | 0.11     |
| mse_q0    | 0.251    |
| mse_q1    | 0.0926   |
| mse_q2    | 0.06     |
| mse_q3    | 0.0446   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.00301  |
| vb_q0     | 0.00893  |
| vb_q1     | 0.000471 |
| vb_q2     | 0.000302 |
| vb_q3     | 0.00266  |
------------------------
------------------------
| grad_norm | 0.464    |
| loss      | 0.117    |
| loss_q0   | 0.257    |
| loss_q1   | 0.0931   |
| loss_q2   | 0.0577   |
| loss_q3   | 0.046    |
| mse       | 0.114    |
| mse_q0    | 0.248    |
| mse_q1    | 0.0926   |
| mse_q2    | 0.0574   |
| mse_q3    | 0.0423   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.00356  |
| vb_q0     | 0.0091   |
| vb_q1     | 0.000472 |
| vb_q2     | 0.000289 |
| vb_q3     | 0.00372  |
------------------------
------------------------
| grad_norm | 0.454    |
| loss      | 0.123    |
| loss_q0   | 0.271    |
| loss_q1   | 0.0896   |
| loss_q2   | 0.0555   |
| loss_q3   | 0.0431   |
| mse       | 0.117    |
| mse_q0    | 0.251    |
| mse_q1    | 0.0892   |
| mse_q2    | 0.0552   |
| mse_q3    | 0.0408   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00653  |
| vb_q0     | 0.0204   |
| vb_q1     | 0.000456 |
| vb_q2     | 0.000281 |
| vb_q3     | 0.00231  |
------------------------
