Logging to /tmp/openai-2024-02-05-14-44-21-035479
creating model and diffusion...
Number of Model Parameters on Rank 0: 52546438
creating data loader...
training...
Number of Model Parameters on Rank 1: 52546438
------------------------
| grad_norm | 3.04     |
| loss      | 1.01     |
| loss_q0   | 1.04     |
| loss_q1   | 1        |
| loss_q2   | 1        |
| loss_q3   | 1.01     |
| mse       | 1        |
| mse_q0    | 1.02     |
| mse_q1    | 0.998    |
| mse_q2    | 0.998    |
| mse_q3    | 0.997    |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0115   |
| vb_q0     | 0.0193   |
| vb_q1     | 0.00476  |
| vb_q2     | 0.00495  |
| vb_q3     | 0.0149   |
------------------------
------------------------
| grad_norm | 3.04     |
| loss      | 0.925    |
| loss_q0   | 0.948    |
| loss_q1   | 0.909    |
| loss_q2   | 0.909    |
| loss_q3   | 0.933    |
| mse       | 0.911    |
| mse_q0    | 0.927    |
| mse_q1    | 0.905    |
| mse_q2    | 0.905    |
| mse_q3    | 0.906    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0145   |
| vb_q0     | 0.0214   |
| vb_q1     | 0.00448  |
| vb_q2     | 0.00456  |
| vb_q3     | 0.0264   |
------------------------
------------------------
| grad_norm | 2.85     |
| loss      | 0.766    |
| loss_q0   | 0.815    |
| loss_q1   | 0.721    |
| loss_q2   | 0.725    |
| loss_q3   | 0.795    |
| mse       | 0.736    |
| mse_q0    | 0.786    |
| mse_q1    | 0.718    |
| mse_q2    | 0.722    |
| mse_q3    | 0.721    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0299   |
| vb_q0     | 0.0284   |
| vb_q1     | 0.0036   |
| vb_q2     | 0.00371  |
| vb_q3     | 0.0746   |
------------------------
------------------------
| grad_norm | 2.48     |
| loss      | 0.617    |
| loss_q0   | 0.698    |
| loss_q1   | 0.573    |
| loss_q2   | 0.56     |
| loss_q3   | 0.629    |
| mse       | 0.59     |
| mse_q0    | 0.66     |
| mse_q1    | 0.57     |
| mse_q2    | 0.557    |
| mse_q3    | 0.566    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0275   |
| vb_q0     | 0.0382   |
| vb_q1     | 0.00286  |
| vb_q2     | 0.0028   |
| vb_q3     | 0.0634   |
------------------------
------------------------
| grad_norm | 2.19     |
| loss      | 0.47     |
| loss_q0   | 0.561    |
| loss_q1   | 0.448    |
| loss_q2   | 0.44     |
| loss_q3   | 0.449    |
| mse       | 0.46     |
| mse_q0    | 0.545    |
| mse_q1    | 0.446    |
| mse_q2    | 0.437    |
| mse_q3    | 0.427    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.00996  |
| vb_q0     | 0.0161   |
| vb_q1     | 0.00222  |
| vb_q2     | 0.00222  |
| vb_q3     | 0.0218   |
------------------------
------------------------
| grad_norm | 1.86     |
| loss      | 0.391    |
| loss_q0   | 0.533    |
| loss_q1   | 0.352    |
| loss_q2   | 0.336    |
| loss_q3   | 0.342    |
| mse       | 0.376    |
| mse_q0    | 0.486    |
| mse_q1    | 0.35     |
| mse_q2    | 0.334    |
| mse_q3    | 0.331    |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.0152   |
| vb_q0     | 0.0476   |
| vb_q1     | 0.00177  |
| vb_q2     | 0.00171  |
| vb_q3     | 0.0111   |
------------------------
------------------------
| grad_norm | 1.62     |
| loss      | 0.306    |
| loss_q0   | 0.424    |
| loss_q1   | 0.279    |
| loss_q2   | 0.264    |
| loss_q3   | 0.275    |
| mse       | 0.297    |
| mse_q0    | 0.41     |
| mse_q1    | 0.278    |
| mse_q2    | 0.263    |
| mse_q3    | 0.254    |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.00907  |
| vb_q0     | 0.0141   |
| vb_q1     | 0.00139  |
| vb_q2     | 0.00135  |
| vb_q3     | 0.0203   |
------------------------
------------------------
| grad_norm | 1.38     |
| loss      | 0.258    |
| loss_q0   | 0.391    |
| loss_q1   | 0.23     |
| loss_q2   | 0.203    |
| loss_q3   | 0.204    |
| mse       | 0.25     |
| mse_q0    | 0.369    |
| mse_q1    | 0.229    |
| mse_q2    | 0.202    |
| mse_q3    | 0.197    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.00776  |
| vb_q0     | 0.022    |
| vb_q1     | 0.00115  |
| vb_q2     | 0.00103  |
| vb_q3     | 0.00623  |
------------------------
------------------------
| grad_norm | 1.21     |
| loss      | 0.224    |
| loss_q0   | 0.373    |
| loss_q1   | 0.19     |
| loss_q2   | 0.165    |
| loss_q3   | 0.164    |
| mse       | 0.214    |
| mse_q0    | 0.345    |
| mse_q1    | 0.189    |
| mse_q2    | 0.165    |
| mse_q3    | 0.156    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00953  |
| vb_q0     | 0.0282   |
| vb_q1     | 0.000955 |
| vb_q2     | 0.000836 |
| vb_q3     | 0.00761  |
------------------------
------------------------
| grad_norm | 1.07     |
| loss      | 0.185    |
| loss_q0   | 0.333    |
| loss_q1   | 0.16     |
| loss_q2   | 0.136    |
| loss_q3   | 0.125    |
| mse       | 0.179    |
| mse_q0    | 0.314    |
| mse_q1    | 0.159    |
| mse_q2    | 0.135    |
| mse_q3    | 0.121    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00569  |
| vb_q0     | 0.0181   |
| vb_q1     | 0.000801 |
| vb_q2     | 0.00068  |
| vb_q3     | 0.00358  |
------------------------
------------------------
| grad_norm | 0.923    |
| loss      | 0.18     |
| loss_q0   | 0.338    |
| loss_q1   | 0.139    |
| loss_q2   | 0.112    |
| loss_q3   | 0.104    |
| mse       | 0.166    |
| mse_q0    | 0.291    |
| mse_q1    | 0.138    |
| mse_q2    | 0.111    |
| mse_q3    | 0.101    |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.0143   |
| vb_q0     | 0.0469   |
| vb_q1     | 0.000698 |
| vb_q2     | 0.000568 |
| vb_q3     | 0.00287  |
------------------------
------------------------
| grad_norm | 0.817    |
| loss      | 0.158    |
| loss_q0   | 0.308    |
| loss_q1   | 0.125    |
| loss_q2   | 0.0979   |
| loss_q3   | 0.0879   |
| mse       | 0.15     |
| mse_q0    | 0.281    |
| mse_q1    | 0.125    |
| mse_q2    | 0.0974   |
| mse_q3    | 0.0847   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.00787  |
| vb_q0     | 0.0267   |
| vb_q1     | 0.000635 |
| vb_q2     | 0.000495 |
| vb_q3     | 0.00321  |
------------------------
------------------------
| grad_norm | 0.749    |
| loss      | 0.135    |
| loss_q0   | 0.294    |
| loss_q1   | 0.115    |
| loss_q2   | 0.085    |
| loss_q3   | 0.0733   |
| mse       | 0.13     |
| mse_q0    | 0.276    |
| mse_q1    | 0.115    |
| mse_q2    | 0.0846   |
| mse_q3    | 0.0717   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.00473  |
| vb_q0     | 0.0185   |
| vb_q1     | 0.000586 |
| vb_q2     | 0.000424 |
| vb_q3     | 0.00155  |
------------------------
------------------------
| grad_norm | 0.679    |
| loss      | 0.136    |
| loss_q0   | 0.278    |
| loss_q1   | 0.108    |
| loss_q2   | 0.0753   |
| loss_q3   | 0.0638   |
| mse       | 0.131    |
| mse_q0    | 0.262    |
| mse_q1    | 0.108    |
| mse_q2    | 0.075    |
| mse_q3    | 0.0614   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.00508  |
| vb_q0     | 0.0159   |
| vb_q1     | 0.000549 |
| vb_q2     | 0.00038  |
| vb_q3     | 0.0024   |
------------------------
------------------------
| grad_norm | 0.614    |
| loss      | 0.323    |
| loss_q0   | 0.251    |
| loss_q1   | 0.102    |
| loss_q2   | 0.0694   |
| loss_q3   | 0.874    |
| mse       | 0.116    |
| mse_q0    | 0.243    |
| mse_q1    | 0.101    |
| mse_q2    | 0.069    |
| mse_q3    | 0.0548   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.207    |
| vb_q0     | 0.00807  |
| vb_q1     | 0.000529 |
| vb_q2     | 0.000347 |
| vb_q3     | 0.819    |
------------------------
------------------------
| grad_norm | 0.567    |
| loss      | 0.325    |
| loss_q0   | 0.272    |
| loss_q1   | 0.0971   |
| loss_q2   | 0.064    |
| loss_q3   | 0.881    |
| mse       | 0.114    |
| mse_q0    | 0.256    |
| mse_q1    | 0.0966   |
| mse_q2    | 0.0637   |
| mse_q3    | 0.0495   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.211    |
| vb_q0     | 0.0163   |
| vb_q1     | 0.000498 |
| vb_q2     | 0.000321 |
| vb_q3     | 0.831    |
------------------------
------------------------
| grad_norm | 0.539    |
| loss      | 0.321    |
| loss_q0   | 0.237    |
| loss_q1   | 0.0911   |
| loss_q2   | 0.0599   |
| loss_q3   | 0.872    |
| mse       | 0.105    |
| mse_q0    | 0.23     |
| mse_q1    | 0.0906   |
| mse_q2    | 0.0596   |
| mse_q3    | 0.0459   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.216    |
| vb_q0     | 0.00702  |
| vb_q1     | 0.000461 |
| vb_q2     | 0.0003   |
| vb_q3     | 0.826    |
------------------------
------------------------
| grad_norm | 0.519    |
| loss      | 0.126    |
| loss_q0   | 0.292    |
| loss_q1   | 0.0891   |
| loss_q2   | 0.0575   |
| loss_q3   | 0.0431   |
| mse       | 0.118    |
| mse_q0    | 0.262    |
| mse_q1    | 0.0887   |
| mse_q2    | 0.0572   |
| mse_q3    | 0.0418   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.00856  |
| vb_q0     | 0.0292   |
| vb_q1     | 0.00046  |
| vb_q2     | 0.000288 |
| vb_q3     | 0.0013   |
------------------------
------------------------
| grad_norm | 0.499    |
| loss      | 0.112    |
| loss_q0   | 0.288    |
| loss_q1   | 0.0849   |
| loss_q2   | 0.0561   |
| loss_q3   | 0.0421   |
| mse       | 0.104    |
| mse_q0    | 0.251    |
| mse_q1    | 0.0845   |
| mse_q2    | 0.0558   |
| mse_q3    | 0.0413   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.00861  |
| vb_q0     | 0.0368   |
| vb_q1     | 0.000429 |
| vb_q2     | 0.000279 |
| vb_q3     | 0.000815 |
------------------------
------------------------
| grad_norm | 0.465    |
| loss      | 0.107    |
| loss_q0   | 0.243    |
| loss_q1   | 0.085    |
| loss_q2   | 0.0545   |
| loss_q3   | 0.0404   |
| mse       | 0.104    |
| mse_q0    | 0.235    |
| mse_q1    | 0.0846   |
| mse_q2    | 0.0542   |
| mse_q3    | 0.0386   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00247  |
| vb_q0     | 0.00756  |
| vb_q1     | 0.00043  |
| vb_q2     | 0.000268 |
| vb_q3     | 0.00171  |
------------------------
