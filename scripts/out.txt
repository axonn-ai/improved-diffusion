WORLD SIZE: 1
CUDA AVAILABLE: True
Logging to /tmp/openai-2024-01-10-10-49-12-143288
creating model and diffusion...
creating data loader...
training...
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 2.97     |
| loss      | 1.04     |
| loss_q0   | 1.02     |
| loss_q1   | 0.992    |
| loss_q2   | 0.999    |
| loss_q3   | 1.14     |
| mse       | 0.993    |
| mse_q0    | 0.995    |
| mse_q1    | 0.987    |
| mse_q2    | 0.994    |
| mse_q3    | 0.995    |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0434   |
| vb_q0     | 0.0248   |
| vb_q1     | 0.00485  |
| vb_q2     | 0.00512  |
| vb_q3     | 0.144    |
------------------------
saving model 0...
saving model 0.9999...
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 3        |
| loss      | 0.93     |
| loss_q0   | 0.956    |
| loss_q1   | 0.906    |
| loss_q2   | 0.906    |
| loss_q3   | 0.953    |
| mse       | 0.91     |
| mse_q0    | 0.933    |
| mse_q1    | 0.902    |
| mse_q2    | 0.901    |
| mse_q3    | 0.901    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0207   |
| vb_q0     | 0.0231   |
| vb_q1     | 0.00452  |
| vb_q2     | 0.00455  |
| vb_q3     | 0.052    |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 2.82     |
| loss      | 0.747    |
| loss_q0   | 0.801    |
| loss_q1   | 0.719    |
| loss_q2   | 0.721    |
| loss_q3   | 0.741    |
| mse       | 0.735    |
| mse_q0    | 0.782    |
| mse_q1    | 0.716    |
| mse_q2    | 0.717    |
| mse_q3    | 0.719    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0122   |
| vb_q0     | 0.0194   |
| vb_q1     | 0.00357  |
| vb_q2     | 0.0036   |
| vb_q3     | 0.0212   |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 2.52     |
| loss      | 0.593    |
| loss_q0   | 0.669    |
| loss_q1   | 0.568    |
| loss_q2   | 0.562    |
| loss_q3   | 0.582    |
| mse       | 0.581    |
| mse_q0    | 0.649    |
| mse_q1    | 0.566    |
| mse_q2    | 0.56     |
| mse_q3    | 0.558    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0122   |
| vb_q0     | 0.0201   |
| vb_q1     | 0.00285  |
| vb_q2     | 0.00285  |
| vb_q3     | 0.0247   |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 2.16     |
| loss      | 0.473    |
| loss_q0   | 0.56     |
| loss_q1   | 0.444    |
| loss_q2   | 0.433    |
| loss_q3   | 0.45     |
| mse       | 0.462    |
| mse_q0    | 0.539    |
| mse_q1    | 0.442    |
| mse_q2    | 0.431    |
| mse_q3    | 0.431    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.0114   |
| vb_q0     | 0.0205   |
| vb_q1     | 0.00221  |
| vb_q2     | 0.00217  |
| vb_q3     | 0.019    |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 1.87     |
| loss      | 1.19     |
| loss_q0   | 0.498    |
| loss_q1   | 0.347    |
| loss_q2   | 0.333    |
| loss_q3   | 3.47     |
| mse       | 0.366    |
| mse_q0    | 0.459    |
| mse_q1    | 0.345    |
| mse_q2    | 0.331    |
| mse_q3    | 0.33     |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.826    |
| vb_q0     | 0.0395   |
| vb_q1     | 0.00173  |
| vb_q2     | 0.00168  |
| vb_q3     | 3.14     |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 1.6      |
| loss      | 0.895    |
| loss_q0   | 0.412    |
| loss_q1   | 0.277    |
| loss_q2   | 0.257    |
| loss_q3   | 2.66     |
| mse       | 0.297    |
| mse_q0    | 0.399    |
| mse_q1    | 0.276    |
| mse_q2    | 0.256    |
| mse_q3    | 0.25     |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.598    |
| vb_q0     | 0.0129   |
| vb_q1     | 0.00138  |
| vb_q2     | 0.0013   |
| vb_q3     | 2.41     |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 1.39     |
| loss      | 0.245    |
| loss_q0   | 0.358    |
| loss_q1   | 0.225    |
| loss_q2   | 0.201    |
| loss_q3   | 0.196    |
| mse       | 0.24     |
| mse_q0    | 0.348    |
| mse_q1    | 0.224    |
| mse_q2    | 0.2      |
| mse_q3    | 0.191    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.00463  |
| vb_q0     | 0.0103   |
| vb_q1     | 0.00112  |
| vb_q2     | 0.00102  |
| vb_q3     | 0.00575  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 1.19     |
| loss      | 0.204    |
| loss_q0   | 0.323    |
| loss_q1   | 0.184    |
| loss_q2   | 0.159    |
| loss_q3   | 0.155    |
| mse       | 0.199    |
| mse_q0    | 0.311    |
| mse_q1    | 0.183    |
| mse_q2    | 0.159    |
| mse_q3    | 0.149    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00463  |
| vb_q0     | 0.0119   |
| vb_q1     | 0.000924 |
| vb_q2     | 0.000809 |
| vb_q3     | 0.00559  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 1.03     |
| loss      | 0.18     |
| loss_q0   | 0.309    |
| loss_q1   | 0.157    |
| loss_q2   | 0.128    |
| loss_q3   | 0.122    |
| mse       | 0.175    |
| mse_q0    | 0.295    |
| mse_q1    | 0.156    |
| mse_q2    | 0.127    |
| mse_q3    | 0.118    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00497  |
| vb_q0     | 0.014    |
| vb_q1     | 0.000794 |
| vb_q2     | 0.000639 |
| vb_q3     | 0.0043   |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.912    |
| loss      | 0.16     |
| loss_q0   | 0.295    |
| loss_q1   | 0.134    |
| loss_q2   | 0.106    |
| loss_q3   | 0.0998   |
| mse       | 0.153    |
| mse_q0    | 0.275    |
| mse_q1    | 0.133    |
| mse_q2    | 0.106    |
| mse_q3    | 0.0949   |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.00663  |
| vb_q0     | 0.0199   |
| vb_q1     | 0.000681 |
| vb_q2     | 0.000529 |
| vb_q3     | 0.00488  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.794    |
| loss      | 0.15     |
| loss_q0   | 0.299    |
| loss_q1   | 0.119    |
| loss_q2   | 0.0903   |
| loss_q3   | 0.0811   |
| mse       | 0.145    |
| mse_q0    | 0.284    |
| mse_q1    | 0.118    |
| mse_q2    | 0.0898   |
| mse_q3    | 0.078    |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.00514  |
| vb_q0     | 0.0158   |
| vb_q1     | 0.000602 |
| vb_q2     | 0.000452 |
| vb_q3     | 0.00303  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.721    |
| loss      | 0.133    |
| loss_q0   | 0.281    |
| loss_q1   | 0.106    |
| loss_q2   | 0.0784   |
| loss_q3   | 0.0678   |
| mse       | 0.128    |
| mse_q0    | 0.265    |
| mse_q1    | 0.106    |
| mse_q2    | 0.078    |
| mse_q3    | 0.0653   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.00481  |
| vb_q0     | 0.0162   |
| vb_q1     | 0.000533 |
| vb_q2     | 0.000395 |
| vb_q3     | 0.00251  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.658    |
| loss      | 0.126    |
| loss_q0   | 0.279    |
| loss_q1   | 0.1      |
| loss_q2   | 0.07     |
| loss_q3   | 0.0598   |
| mse       | 0.121    |
| mse_q0    | 0.262    |
| mse_q1    | 0.0995   |
| mse_q2    | 0.0697   |
| mse_q3    | 0.0561   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.00527  |
| vb_q0     | 0.0167   |
| vb_q1     | 0.000508 |
| vb_q2     | 0.00035  |
| vb_q3     | 0.00365  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.596    |
| loss      | 0.215    |
| loss_q0   | 0.259    |
| loss_q1   | 0.0947   |
| loss_q2   | 0.0639   |
| loss_q3   | 0.434    |
| mse       | 0.108    |
| mse_q0    | 0.248    |
| mse_q1    | 0.0942   |
| mse_q2    | 0.0636   |
| mse_q3    | 0.0497   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.107    |
| vb_q0     | 0.0112   |
| vb_q1     | 0.000484 |
| vb_q2     | 0.000319 |
| vb_q3     | 0.385    |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.569    |
| loss      | 0.188    |
| loss_q0   | 0.242    |
| loss_q1   | 0.09     |
| loss_q2   | 0.0595   |
| loss_q3   | 0.373    |
| mse       | 0.108    |
| mse_q0    | 0.232    |
| mse_q1    | 0.0895   |
| mse_q2    | 0.0592   |
| mse_q3    | 0.0453   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.0805   |
| vb_q0     | 0.0102   |
| vb_q1     | 0.00046  |
| vb_q2     | 0.000298 |
| vb_q3     | 0.328    |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.526    |
| loss      | 0.112    |
| loss_q0   | 0.269    |
| loss_q1   | 0.0877   |
| loss_q2   | 0.0549   |
| loss_q3   | 0.0431   |
| mse       | 0.106    |
| mse_q0    | 0.251    |
| mse_q1    | 0.0872   |
| mse_q2    | 0.0547   |
| mse_q3    | 0.0412   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.00512  |
| vb_q0     | 0.0187   |
| vb_q1     | 0.000446 |
| vb_q2     | 0.000274 |
| vb_q3     | 0.00191  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.488    |
| loss      | 0.109    |
| loss_q0   | 0.272    |
| loss_q1   | 0.0835   |
| loss_q2   | 0.0528   |
| loss_q3   | 0.041    |
| mse       | 0.104    |
| mse_q0    | 0.256    |
| mse_q1    | 0.0831   |
| mse_q2    | 0.0526   |
| mse_q3    | 0.0386   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.00452  |
| vb_q0     | 0.0161   |
| vb_q1     | 0.000425 |
| vb_q2     | 0.000264 |
| vb_q3     | 0.00236  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.463    |
| loss      | 0.102    |
| loss_q0   | 0.263    |
| loss_q1   | 0.0798   |
| loss_q2   | 0.0507   |
| loss_q3   | 0.0376   |
| mse       | 0.0956   |
| mse_q0    | 0.236    |
| mse_q1    | 0.0793   |
| mse_q2    | 0.0504   |
| mse_q3    | 0.0364   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.0064   |
| vb_q0     | 0.027    |
| vb_q1     | 0.000405 |
| vb_q2     | 0.000252 |
| vb_q3     | 0.00119  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
------------------------
| grad_norm | 0.449    |
| loss      | 0.102    |
| loss_q0   | 0.225    |
| loss_q1   | 0.0807   |
| loss_q2   | 0.0498   |
| loss_q3   | 0.0361   |
| mse       | 0.0983   |
| mse_q0    | 0.215    |
| mse_q1    | 0.0803   |
| mse_q2    | 0.0495   |
| mse_q3    | 0.035    |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00321  |
| vb_q0     | 0.0103   |
| vb_q1     | 0.000408 |
| vb_q2     | 0.000247 |
| vb_q3     | 0.00106  |
------------------------
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
batch.shape[0]: 128
self.microbatch: 128
saving model 0...
saving model 0.9999...
