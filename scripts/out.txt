WORLD SIZE: 1
CUDA AVAILABLE: True
Logging to /tmp/openai-2024-01-05-12-30-47-452686
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 2.95     |
| loss      | 1.01     |
| loss_q0   | 1.01     |
| loss_q1   | 0.998    |
| loss_q2   | 1        |
| loss_q3   | 1.03     |
| mse       | 0.998    |
| mse_q0    | 0.997    |
| mse_q1    | 0.993    |
| mse_q2    | 0.998    |
| mse_q3    | 1        |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0135   |
| vb_q0     | 0.0167   |
| vb_q1     | 0.00488  |
| vb_q2     | 0.0051   |
| vb_q3     | 0.0246   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 2.99     |
| loss      | 2.96     |
| loss_q0   | 0.976    |
| loss_q1   | 0.91     |
| loss_q2   | 0.909    |
| loss_q3   | 9.67     |
| mse       | 0.912    |
| mse_q0    | 0.941    |
| mse_q1    | 0.906    |
| mse_q2    | 0.905    |
| mse_q3    | 0.896    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 2.05     |
| vb_q0     | 0.0351   |
| vb_q1     | 0.00454  |
| vb_q2     | 0.00459  |
| vb_q3     | 8.78     |
------------------------
------------------------
| grad_norm | 2.86     |
| loss      | 0.748    |
| loss_q0   | 0.804    |
| loss_q1   | 0.726    |
| loss_q2   | 0.718    |
| loss_q3   | 0.745    |
| mse       | 0.734    |
| mse_q0    | 0.78     |
| mse_q1    | 0.723    |
| mse_q2    | 0.714    |
| mse_q3    | 0.72     |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0141   |
| vb_q0     | 0.0236   |
| vb_q1     | 0.00364  |
| vb_q2     | 0.00367  |
| vb_q3     | 0.025    |
------------------------
------------------------
| grad_norm | 2.51     |
| loss      | 1.69     |
| loss_q0   | 0.669    |
| loss_q1   | 0.57     |
| loss_q2   | 0.561    |
| loss_q3   | 4.92     |
| mse       | 0.582    |
| mse_q0    | 0.644    |
| mse_q1    | 0.567    |
| mse_q2    | 0.558    |
| mse_q3    | 0.555    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 1.1      |
| vb_q0     | 0.0249   |
| vb_q1     | 0.00282  |
| vb_q2     | 0.00283  |
| vb_q3     | 4.37     |
------------------------
------------------------
| grad_norm | 2.18     |
| loss      | 0.471    |
| loss_q0   | 0.566    |
| loss_q1   | 0.445    |
| loss_q2   | 0.429    |
| loss_q3   | 0.449    |
| mse       | 0.459    |
| mse_q0    | 0.543    |
| mse_q1    | 0.443    |
| mse_q2    | 0.427    |
| mse_q3    | 0.429    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.0121   |
| vb_q0     | 0.0232   |
| vb_q1     | 0.00224  |
| vb_q2     | 0.00215  |
| vb_q3     | 0.02     |
------------------------
------------------------
| grad_norm | 1.88     |
| loss      | 0.373    |
| loss_q0   | 0.471    |
| loss_q1   | 0.352    |
| loss_q2   | 0.333    |
| loss_q3   | 0.334    |
| mse       | 0.366    |
| mse_q0    | 0.456    |
| mse_q1    | 0.35     |
| mse_q2    | 0.331    |
| mse_q3    | 0.323    |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.00727  |
| vb_q0     | 0.0144   |
| vb_q1     | 0.00174  |
| vb_q2     | 0.00168  |
| vb_q3     | 0.0115   |
------------------------
------------------------
| grad_norm | 1.62     |
| loss      | 0.302    |
| loss_q0   | 0.419    |
| loss_q1   | 0.277    |
| loss_q2   | 0.255    |
| loss_q3   | 0.261    |
| mse       | 0.293    |
| mse_q0    | 0.398    |
| mse_q1    | 0.276    |
| mse_q2    | 0.254    |
| mse_q3    | 0.247    |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.00911  |
| vb_q0     | 0.0211   |
| vb_q1     | 0.00139  |
| vb_q2     | 0.00129  |
| vb_q3     | 0.0132   |
------------------------
------------------------
| grad_norm | 1.38     |
| loss      | 0.637    |
| loss_q0   | 0.386    |
| loss_q1   | 0.222    |
| loss_q2   | 0.198    |
| loss_q3   | 1.72     |
| mse       | 0.242    |
| mse_q0    | 0.36     |
| mse_q1    | 0.221    |
| mse_q2    | 0.197    |
| mse_q3    | 0.191    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.395    |
| vb_q0     | 0.0262   |
| vb_q1     | 0.00111  |
| vb_q2     | 0.000993 |
| vb_q3     | 1.53     |
------------------------
------------------------
| grad_norm | 1.2      |
| loss      | 0.797    |
| loss_q0   | 0.341    |
| loss_q1   | 0.184    |
| loss_q2   | 0.158    |
| loss_q3   | 2.46     |
| mse       | 0.203    |
| mse_q0    | 0.328    |
| mse_q1    | 0.184    |
| mse_q2    | 0.158    |
| mse_q3    | 0.149    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.594    |
| vb_q0     | 0.0131   |
| vb_q1     | 0.000922 |
| vb_q2     | 0.000794 |
| vb_q3     | 2.31     |
------------------------
------------------------
| grad_norm | 1.04     |
| loss      | 0.189    |
| loss_q0   | 0.323    |
| loss_q1   | 0.157    |
| loss_q2   | 0.128    |
| loss_q3   | 0.131    |
| mse       | 0.179    |
| mse_q0    | 0.302    |
| mse_q1    | 0.156    |
| mse_q2    | 0.127    |
| mse_q3    | 0.118    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00905  |
| vb_q0     | 0.0212   |
| vb_q1     | 0.000788 |
| vb_q2     | 0.000641 |
| vb_q3     | 0.0127   |
------------------------
------------------------
| grad_norm | 0.923    |
| loss      | 0.338    |
| loss_q0   | 0.291    |
| loss_q1   | 0.135    |
| loss_q2   | 0.107    |
| loss_q3   | 0.794    |
| mse       | 0.15     |
| mse_q0    | 0.279    |
| mse_q1    | 0.135    |
| mse_q2    | 0.107    |
| mse_q3    | 0.0957   |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.188    |
| vb_q0     | 0.0125   |
| vb_q1     | 0.000682 |
| vb_q2     | 0.000534 |
| vb_q3     | 0.698    |
------------------------
------------------------
| grad_norm | 0.814    |
| loss      | 0.147    |
| loss_q0   | 0.296    |
| loss_q1   | 0.118    |
| loss_q2   | 0.0909   |
| loss_q3   | 0.0812   |
| mse       | 0.141    |
| mse_q0    | 0.278    |
| mse_q1    | 0.118    |
| mse_q2    | 0.0904   |
| mse_q3    | 0.0781   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.00581  |
| vb_q0     | 0.0187   |
| vb_q1     | 0.000598 |
| vb_q2     | 0.000453 |
| vb_q3     | 0.00309  |
------------------------
------------------------
| grad_norm | 0.734    |
| loss      | 0.136    |
| loss_q0   | 0.306    |
| loss_q1   | 0.109    |
| loss_q2   | 0.0798   |
| loss_q3   | 0.0697   |
| mse       | 0.128    |
| mse_q0    | 0.274    |
| mse_q1    | 0.108    |
| mse_q2    | 0.0794   |
| mse_q3    | 0.065    |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.0087   |
| vb_q0     | 0.032    |
| vb_q1     | 0.00055  |
| vb_q2     | 0.000394 |
| vb_q3     | 0.0047   |
------------------------
------------------------
| grad_norm | 0.653    |
| loss      | 0.24     |
| loss_q0   | 0.277    |
| loss_q1   | 0.102    |
| loss_q2   | 0.0696   |
| loss_q3   | 0.522    |
| mse       | 0.119    |
| mse_q0    | 0.247    |
| mse_q1    | 0.101    |
| mse_q2    | 0.0693   |
| mse_q3    | 0.057    |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.121    |
| vb_q0     | 0.0299   |
| vb_q1     | 0.000515 |
| vb_q2     | 0.00035  |
| vb_q3     | 0.465    |
------------------------
------------------------
| grad_norm | 0.602    |
| loss      | 0.212    |
| loss_q0   | 0.287    |
| loss_q1   | 0.0929   |
| loss_q2   | 0.0641   |
| loss_q3   | 0.369    |
| mse       | 0.114    |
| mse_q0    | 0.256    |
| mse_q1    | 0.0924   |
| mse_q2    | 0.0638   |
| mse_q3    | 0.0497   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.0975   |
| vb_q0     | 0.0309   |
| vb_q1     | 0.000467 |
| vb_q2     | 0.000321 |
| vb_q3     | 0.32     |
------------------------
------------------------
| grad_norm | 0.551    |
| loss      | 0.121    |
| loss_q0   | 0.279    |
| loss_q1   | 0.089    |
| loss_q2   | 0.0596   |
| loss_q3   | 0.0476   |
| mse       | 0.113    |
| mse_q0    | 0.249    |
| mse_q1    | 0.0886   |
| mse_q2    | 0.0593   |
| mse_q3    | 0.0443   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.00857  |
| vb_q0     | 0.0292   |
| vb_q1     | 0.000452 |
| vb_q2     | 0.000298 |
| vb_q3     | 0.00329  |
------------------------
------------------------
| grad_norm | 0.525    |
| loss      | 0.11     |
| loss_q0   | 0.251    |
| loss_q1   | 0.0862   |
| loss_q2   | 0.0552   |
| loss_q3   | 0.0426   |
| mse       | 0.105    |
| mse_q0    | 0.233    |
| mse_q1    | 0.0858   |
| mse_q2    | 0.0549   |
| mse_q3    | 0.0415   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.00483  |
| vb_q0     | 0.0172   |
| vb_q1     | 0.000436 |
| vb_q2     | 0.000279 |
| vb_q3     | 0.00109  |
------------------------
------------------------
| grad_norm | 0.499    |
| loss      | 0.118    |
| loss_q0   | 0.283    |
| loss_q1   | 0.0857   |
| loss_q2   | 0.0523   |
| loss_q3   | 0.0394   |
| mse       | 0.107    |
| mse_q0    | 0.245    |
| mse_q1    | 0.0853   |
| mse_q2    | 0.052    |
| mse_q3    | 0.0383   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.0104   |
| vb_q0     | 0.0376   |
| vb_q1     | 0.000435 |
| vb_q2     | 0.000263 |
| vb_q3     | 0.00113  |
------------------------
------------------------
| grad_norm | 0.471    |
| loss      | 0.181    |
| loss_q0   | 0.243    |
| loss_q1   | 0.085    |
| loss_q2   | 0.0522   |
| loss_q3   | 0.344    |
| mse       | 0.102    |
| mse_q0    | 0.232    |
| mse_q1    | 0.0845   |
| mse_q2    | 0.0519   |
| mse_q3    | 0.0371   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.0785   |
| vb_q0     | 0.0109   |
| vb_q1     | 0.000436 |
| vb_q2     | 0.00026  |
| vb_q3     | 0.307    |
------------------------
------------------------
| grad_norm | 0.455    |
| loss      | 0.11     |
| loss_q0   | 0.248    |
| loss_q1   | 0.081    |
| loss_q2   | 0.0496   |
| loss_q3   | 0.0375   |
| mse       | 0.105    |
| mse_q0    | 0.232    |
| mse_q1    | 0.0806   |
| mse_q2    | 0.0494   |
| mse_q3    | 0.0358   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00496  |
| vb_q0     | 0.0155   |
| vb_q1     | 0.000416 |
| vb_q2     | 0.000248 |
| vb_q3     | 0.00171  |
------------------------
saving model 0...
saving model 0.9999...
