WORLD SIZE: 1
CUDA AVAILABLE: True
Logging to /tmp/openai-2024-01-10-11-02-37-956932
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 2.89     |
| loss      | 1.01     |
| loss_q0   | 1.01     |
| loss_q1   | 1        |
| loss_q2   | 1        |
| loss_q3   | 1.04     |
| mse       | 0.999    |
| mse_q0    | 0.996    |
| mse_q1    | 0.997    |
| mse_q2    | 0.997    |
| mse_q3    | 1.01     |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0132   |
| vb_q0     | 0.0162   |
| vb_q1     | 0.0049   |
| vb_q2     | 0.00499  |
| vb_q3     | 0.0301   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 3.03     |
| loss      | 0.933    |
| loss_q0   | 0.971    |
| loss_q1   | 0.912    |
| loss_q2   | 0.902    |
| loss_q3   | 0.948    |
| mse       | 0.91     |
| mse_q0    | 0.936    |
| mse_q1    | 0.908    |
| mse_q2    | 0.898    |
| mse_q3    | 0.899    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0227   |
| vb_q0     | 0.0342   |
| vb_q1     | 0.00451  |
| vb_q2     | 0.00456  |
| vb_q3     | 0.0497   |
------------------------
------------------------
| grad_norm | 2.85     |
| loss      | 0.747    |
| loss_q0   | 0.8      |
| loss_q1   | 0.724    |
| loss_q2   | 0.718    |
| loss_q3   | 0.747    |
| mse       | 0.732    |
| mse_q0    | 0.779    |
| mse_q1    | 0.72     |
| mse_q2    | 0.715    |
| mse_q3    | 0.715    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0148   |
| vb_q0     | 0.0212   |
| vb_q1     | 0.00359  |
| vb_q2     | 0.0036   |
| vb_q3     | 0.0312   |
------------------------
------------------------
| grad_norm | 2.5      |
| loss      | 0.597    |
| loss_q0   | 0.694    |
| loss_q1   | 0.569    |
| loss_q2   | 0.559    |
| loss_q3   | 0.571    |
| mse       | 0.581    |
| mse_q0    | 0.653    |
| mse_q1    | 0.566    |
| mse_q2    | 0.557    |
| mse_q3    | 0.555    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0153   |
| vb_q0     | 0.0412   |
| vb_q1     | 0.00287  |
| vb_q2     | 0.00282  |
| vb_q3     | 0.0161   |
------------------------
------------------------
| grad_norm | 2.18     |
| loss      | 0.469    |
| loss_q0   | 0.544    |
| loss_q1   | 0.444    |
| loss_q2   | 0.436    |
| loss_q3   | 0.451    |
| mse       | 0.458    |
| mse_q0    | 0.528    |
| mse_q1    | 0.442    |
| mse_q2    | 0.434    |
| mse_q3    | 0.427    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.0108   |
| vb_q0     | 0.0164   |
| vb_q1     | 0.00222  |
| vb_q2     | 0.0022   |
| vb_q3     | 0.0237   |
------------------------
------------------------
| grad_norm | 1.87     |
| loss      | 0.377    |
| loss_q0   | 0.483    |
| loss_q1   | 0.347    |
| loss_q2   | 0.331    |
| loss_q3   | 0.344    |
| mse       | 0.367    |
| mse_q0    | 0.46     |
| mse_q1    | 0.345    |
| mse_q2    | 0.33     |
| mse_q3    | 0.33     |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.0102   |
| vb_q0     | 0.0229   |
| vb_q1     | 0.00174  |
| vb_q2     | 0.00167  |
| vb_q3     | 0.0141   |
------------------------
------------------------
| grad_norm | 1.61     |
| loss      | 0.958    |
| loss_q0   | 0.413    |
| loss_q1   | 0.273    |
| loss_q2   | 0.257    |
| loss_q3   | 2.91     |
| mse       | 0.293    |
| mse_q0    | 0.396    |
| mse_q1    | 0.272    |
| mse_q2    | 0.255    |
| mse_q3    | 0.248    |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.664    |
| vb_q0     | 0.0165   |
| vb_q1     | 0.00137  |
| vb_q2     | 0.0013   |
| vb_q3     | 2.66     |
------------------------
------------------------
| grad_norm | 1.38     |
| loss      | 0.658    |
| loss_q0   | 0.377    |
| loss_q1   | 0.221    |
| loss_q2   | 0.2      |
| loss_q3   | 1.84     |
| mse       | 0.242    |
| mse_q0    | 0.35     |
| mse_q1    | 0.22     |
| mse_q2    | 0.199    |
| mse_q3    | 0.191    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.416    |
| vb_q0     | 0.0268   |
| vb_q1     | 0.00111  |
| vb_q2     | 0.00101  |
| vb_q3     | 1.65     |
------------------------
------------------------
| grad_norm | 1.18     |
| loss      | 0.213    |
| loss_q0   | 0.342    |
| loss_q1   | 0.183    |
| loss_q2   | 0.159    |
| loss_q3   | 0.157    |
| mse       | 0.206    |
| mse_q0    | 0.326    |
| mse_q1    | 0.183    |
| mse_q2    | 0.158    |
| mse_q3    | 0.149    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00649  |
| vb_q0     | 0.0155   |
| vb_q1     | 0.000927 |
| vb_q2     | 0.000794 |
| vb_q3     | 0.00798  |
------------------------
------------------------
| grad_norm | 1.03     |
| loss      | 0.19     |
| loss_q0   | 0.336    |
| loss_q1   | 0.157    |
| loss_q2   | 0.128    |
| loss_q3   | 0.12     |
| mse       | 0.182    |
| mse_q0    | 0.312    |
| mse_q1    | 0.156    |
| mse_q2    | 0.128    |
| mse_q3    | 0.117    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00769  |
| vb_q0     | 0.0237   |
| vb_q1     | 0.000787 |
| vb_q2     | 0.000649 |
| vb_q3     | 0.00378  |
------------------------
------------------------
| grad_norm | 0.917    |
| loss      | 0.159    |
| loss_q0   | 0.296    |
| loss_q1   | 0.134    |
| loss_q2   | 0.107    |
| loss_q3   | 0.0985   |
| mse       | 0.153    |
| mse_q0    | 0.274    |
| mse_q1    | 0.133    |
| mse_q2    | 0.106    |
| mse_q3    | 0.0954   |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.0067   |
| vb_q0     | 0.0219   |
| vb_q1     | 0.000675 |
| vb_q2     | 0.000538 |
| vb_q3     | 0.00309  |
------------------------
------------------------
| grad_norm | 0.806    |
| loss      | 0.142    |
| loss_q0   | 0.291    |
| loss_q1   | 0.12     |
| loss_q2   | 0.0899   |
| loss_q3   | 0.0824   |
| mse       | 0.135    |
| mse_q0    | 0.269    |
| mse_q1    | 0.119    |
| mse_q2    | 0.0894   |
| mse_q3    | 0.0781   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.00642  |
| vb_q0     | 0.0217   |
| vb_q1     | 0.000603 |
| vb_q2     | 0.000454 |
| vb_q3     | 0.00431  |
------------------------
------------------------
| grad_norm | 0.725    |
| loss      | 0.131    |
| loss_q0   | 0.273    |
| loss_q1   | 0.109    |
| loss_q2   | 0.0783   |
| loss_q3   | 0.0677   |
| mse       | 0.127    |
| mse_q0    | 0.261    |
| mse_q1    | 0.109    |
| mse_q2    | 0.0779   |
| mse_q3    | 0.0654   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.00371  |
| vb_q0     | 0.0119   |
| vb_q1     | 0.000551 |
| vb_q2     | 0.000392 |
| vb_q3     | 0.00236  |
------------------------
------------------------
| grad_norm | 0.68     |
| loss      | 0.251    |
| loss_q0   | 0.261    |
| loss_q1   | 0.0999   |
| loss_q2   | 0.0707   |
| loss_q3   | 0.602    |
| mse       | 0.119    |
| mse_q0    | 0.249    |
| mse_q1    | 0.0994   |
| mse_q2    | 0.0703   |
| mse_q3    | 0.0574   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.133    |
| vb_q0     | 0.0122   |
| vb_q1     | 0.000502 |
| vb_q2     | 0.000356 |
| vb_q3     | 0.544    |
------------------------
------------------------
| grad_norm | 0.602    |
| loss      | 0.119    |
| loss_q0   | 0.283    |
| loss_q1   | 0.0939   |
| loss_q2   | 0.0628   |
| loss_q3   | 0.0542   |
| mse       | 0.112    |
| mse_q0    | 0.259    |
| mse_q1    | 0.0935   |
| mse_q2    | 0.0625   |
| mse_q3    | 0.0499   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.00713  |
| vb_q0     | 0.025    |
| vb_q1     | 0.000476 |
| vb_q2     | 0.000317 |
| vb_q3     | 0.00427  |
------------------------
------------------------
| grad_norm | 0.548    |
| loss      | 0.219    |
| loss_q0   | 0.285    |
| loss_q1   | 0.0869   |
| loss_q2   | 0.0589   |
| loss_q3   | 0.444    |
| mse       | 0.109    |
| mse_q0    | 0.25     |
| mse_q1    | 0.0864   |
| mse_q2    | 0.0586   |
| mse_q3    | 0.0448   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.11     |
| vb_q0     | 0.0355   |
| vb_q1     | 0.000434 |
| vb_q2     | 0.000298 |
| vb_q3     | 0.399    |
------------------------
------------------------
| grad_norm | 0.51     |
| loss      | 0.197    |
| loss_q0   | 0.259    |
| loss_q1   | 0.085    |
| loss_q2   | 0.0542   |
| loss_q3   | 0.373    |
| mse       | 0.109    |
| mse_q0    | 0.243    |
| mse_q1    | 0.0846   |
| mse_q2    | 0.0539   |
| mse_q3    | 0.0413   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.0886   |
| vb_q0     | 0.0169   |
| vb_q1     | 0.000429 |
| vb_q2     | 0.000277 |
| vb_q3     | 0.331    |
------------------------
------------------------
| grad_norm | 0.491    |
| loss      | 0.11     |
| loss_q0   | 0.267    |
| loss_q1   | 0.0861   |
| loss_q2   | 0.0526   |
| loss_q3   | 0.0414   |
| mse       | 0.102    |
| mse_q0    | 0.238    |
| mse_q1    | 0.0856   |
| mse_q2    | 0.0524   |
| mse_q3    | 0.0389   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.00786  |
| vb_q0     | 0.0287   |
| vb_q1     | 0.000442 |
| vb_q2     | 0.000264 |
| vb_q3     | 0.00248  |
------------------------
------------------------
| grad_norm | 0.469    |
| loss      | 0.108    |
| loss_q0   | 0.249    |
| loss_q1   | 0.0787   |
| loss_q2   | 0.0515   |
| loss_q3   | 0.0382   |
| mse       | 0.104    |
| mse_q0    | 0.238    |
| mse_q1    | 0.0783   |
| mse_q2    | 0.0512   |
| mse_q3    | 0.0362   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.00386  |
| vb_q0     | 0.0118   |
| vb_q1     | 0.000397 |
| vb_q2     | 0.000259 |
| vb_q3     | 0.00208  |
------------------------
------------------------
| grad_norm | 0.449    |
| loss      | 0.101    |
| loss_q0   | 0.243    |
| loss_q1   | 0.0813   |
| loss_q2   | 0.05     |
| loss_q3   | 0.0369   |
| mse       | 0.0983   |
| mse_q0    | 0.234    |
| mse_q1    | 0.0808   |
| mse_q2    | 0.0497   |
| mse_q3    | 0.0352   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00292  |
| vb_q0     | 0.00968  |
| vb_q1     | 0.000415 |
| vb_q2     | 0.000248 |
| vb_q3     | 0.0017   |
------------------------
saving model 0...
saving model 0.9999...
