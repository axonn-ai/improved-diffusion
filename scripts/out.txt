Logging to /tmp/openai-2023-12-13-13-28-06-215937
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 3.72     |
| loss      | 1        |
| loss_q3   | 1        |
| mse       | 1        |
| mse_q3    | 1        |
| samples   | 1        |
| step      | 0        |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 3.46     |
| loss      | 0.897    |
| loss_q0   | 0.888    |
| loss_q1   | 0.847    |
| loss_q2   | 0.928    |
| loss_q3   | 0.906    |
| mse       | 0.897    |
| mse_q0    | 0.888    |
| mse_q1    | 0.847    |
| mse_q2    | 0.928    |
| mse_q3    | 0.906    |
| samples   | 11       |
| step      | 10       |
------------------------
------------------------
| grad_norm | 3.05     |
| loss      | 0.724    |
| loss_q0   | 0.754    |
| loss_q1   | 0.684    |
| loss_q2   | 0.712    |
| loss_q3   | 0.752    |
| mse       | 0.724    |
| mse_q0    | 0.754    |
| mse_q1    | 0.684    |
| mse_q2    | 0.712    |
| mse_q3    | 0.752    |
| samples   | 21       |
| step      | 20       |
------------------------
------------------------
| grad_norm | 2.91     |
| loss      | 0.577    |
| loss_q0   | 0.592    |
| loss_q3   | 0.562    |
| mse       | 0.577    |
| mse_q0    | 0.592    |
| mse_q3    | 0.562    |
| samples   | 31       |
| step      | 30       |
------------------------
------------------------
| grad_norm | 2.52     |
| loss      | 0.428    |
| loss_q0   | 0.445    |
| loss_q1   | 0.448    |
| loss_q2   | 0.394    |
| loss_q3   | 0.428    |
| mse       | 0.428    |
| mse_q0    | 0.445    |
| mse_q1    | 0.448    |
| mse_q2    | 0.394    |
| mse_q3    | 0.428    |
| samples   | 41       |
| step      | 40       |
------------------------
------------------------
| grad_norm | 2.52     |
| loss      | 0.348    |
| loss_q0   | 0.399    |
| loss_q2   | 0.298    |
| loss_q3   | 0.296    |
| mse       | 0.348    |
| mse_q0    | 0.399    |
| mse_q2    | 0.298    |
| mse_q3    | 0.296    |
| samples   | 51       |
| step      | 50       |
------------------------
------------------------
| grad_norm | 2.05     |
| loss      | 0.26     |
| loss_q0   | 0.431    |
| loss_q1   | 0.217    |
| loss_q3   | 0.218    |
| mse       | 0.26     |
| mse_q0    | 0.431    |
| mse_q1    | 0.217    |
| mse_q3    | 0.218    |
| samples   | 61       |
| step      | 60       |
------------------------
------------------------
| grad_norm | 1.57     |
| loss      | 0.188    |
| loss_q0   | 0.238    |
| loss_q1   | 0.16     |
| loss_q2   | 0.151    |
| loss_q3   | 0.155    |
| mse       | 0.188    |
| mse_q0    | 0.238    |
| mse_q1    | 0.16     |
| mse_q2    | 0.151    |
| mse_q3    | 0.155    |
| samples   | 71       |
| step      | 70       |
------------------------
------------------------
| grad_norm | 2.33     |
| loss      | 0.213    |
| loss_q0   | 0.351    |
| loss_q1   | 0.126    |
| loss_q2   | 0.114    |
| loss_q3   | 0.124    |
| mse       | 0.213    |
| mse_q0    | 0.351    |
| mse_q1    | 0.126    |
| mse_q2    | 0.114    |
| mse_q3    | 0.124    |
| samples   | 81       |
| step      | 80       |
------------------------
------------------------
| grad_norm | 0.915    |
| loss      | 0.0971   |
| loss_q0   | 0.103    |
| loss_q1   | 0.0943   |
| loss_q2   | 0.102    |
| loss_q3   | 0.0878   |
| mse       | 0.0971   |
| mse_q0    | 0.103    |
| mse_q1    | 0.0943   |
| mse_q2    | 0.102    |
| mse_q3    | 0.0878   |
| samples   | 91       |
| step      | 90       |
------------------------
------------------------
| grad_norm | 1.54     |
| loss      | 0.118    |
| loss_q0   | 0.222    |
| loss_q1   | 0.0765   |
| loss_q2   | 0.0678   |
| loss_q3   | 0.0703   |
| mse       | 0.118    |
| mse_q0    | 0.222    |
| mse_q1    | 0.0765   |
| mse_q2    | 0.0678   |
| mse_q3    | 0.0703   |
| samples   | 101      |
| step      | 100      |
------------------------
------------------------
| grad_norm | 1.4      |
| loss      | 0.0961   |
| loss_q0   | 0.24     |
| loss_q1   | 0.0611   |
| loss_q3   | 0.0575   |
| mse       | 0.0961   |
| mse_q0    | 0.24     |
| mse_q1    | 0.0611   |
| mse_q3    | 0.0575   |
| samples   | 111      |
| step      | 110      |
------------------------
------------------------
| grad_norm | 0.597    |
| loss      | 0.0541   |
| loss_q0   | 0.0697   |
| loss_q1   | 0.0529   |
| loss_q2   | 0.0466   |
| loss_q3   | 0.0512   |
| mse       | 0.0541   |
| mse_q0    | 0.0697   |
| mse_q1    | 0.0529   |
| mse_q2    | 0.0466   |
| mse_q3    | 0.0512   |
| samples   | 121      |
| step      | 120      |
------------------------
------------------------
| grad_norm | 0.675    |
| loss      | 0.0566   |
| loss_q0   | 0.123    |
| loss_q1   | 0.0417   |
| loss_q2   | 0.0412   |
| loss_q3   | 0.0384   |
| mse       | 0.0566   |
| mse_q0    | 0.123    |
| mse_q1    | 0.0417   |
| mse_q2    | 0.0412   |
| mse_q3    | 0.0384   |
| samples   | 131      |
| step      | 130      |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | 0.0746   |
| loss_q0   | 0.202    |
| loss_q1   | 0.0492   |
| loss_q2   | 0.0397   |
| loss_q3   | 0.0371   |
| mse       | 0.0746   |
| mse_q0    | 0.202    |
| mse_q1    | 0.0492   |
| mse_q2    | 0.0397   |
| mse_q3    | 0.0371   |
| samples   | 141      |
| step      | 140      |
------------------------
------------------------
| grad_norm | 0.819    |
| loss      | 0.0665   |
| loss_q0   | 0.1      |
| loss_q1   | 0.0496   |
| loss_q2   | 0.0388   |
| loss_q3   | 0.037    |
| mse       | 0.0665   |
| mse_q0    | 0.1      |
| mse_q1    | 0.0496   |
| mse_q2    | 0.0388   |
| mse_q3    | 0.037    |
| samples   | 151      |
| step      | 150      |
------------------------
------------------------
| grad_norm | 0.512    |
| loss      | 0.0461   |
| loss_q0   | 0.0846   |
| loss_q1   | 0.0395   |
| loss_q2   | 0.0336   |
| loss_q3   | 0.0326   |
| mse       | 0.0461   |
| mse_q0    | 0.0846   |
| mse_q1    | 0.0395   |
| mse_q2    | 0.0336   |
| mse_q3    | 0.0326   |
| samples   | 161      |
| step      | 160      |
------------------------
------------------------
| grad_norm | 0.964    |
| loss      | 0.0656   |
| loss_q0   | 0.14     |
| loss_q1   | 0.0342   |
| loss_q2   | 0.0355   |
| loss_q3   | 0.0324   |
| mse       | 0.0656   |
| mse_q0    | 0.14     |
| mse_q1    | 0.0342   |
| mse_q2    | 0.0355   |
| mse_q3    | 0.0324   |
| samples   | 171      |
| step      | 170      |
------------------------
------------------------
| grad_norm | 1.69     |
| loss      | 0.115    |
| loss_q0   | 0.238    |
| loss_q1   | 0.0348   |
| loss_q2   | 0.0328   |
| loss_q3   | 0.031    |
| mse       | 0.115    |
| mse_q0    | 0.238    |
| mse_q1    | 0.0348   |
| mse_q2    | 0.0328   |
| mse_q3    | 0.031    |
| samples   | 181      |
| step      | 180      |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | 0.0795   |
| loss_q0   | 0.179    |
| loss_q1   | 0.0386   |
| loss_q2   | 0.0355   |
| loss_q3   | 0.0352   |
| mse       | 0.0795   |
| mse_q0    | 0.179    |
| mse_q1    | 0.0386   |
| mse_q2    | 0.0355   |
| mse_q3    | 0.0352   |
| samples   | 191      |
| step      | 190      |
------------------------
------------------------
| grad_norm | 0.721    |
| loss      | 0.062    |
| loss_q0   | 0.12     |
| loss_q1   | 0.0403   |
| loss_q2   | 0.0404   |
| loss_q3   | 0.0327   |
| mse       | 0.062    |
| mse_q0    | 0.12     |
| mse_q1    | 0.0403   |
| mse_q2    | 0.0404   |
| mse_q3    | 0.0327   |
| samples   | 201      |
| step      | 200      |
------------------------
------------------------
| grad_norm | 0.356    |
| loss      | 0.0372   |
| loss_q0   | 0.066    |
| loss_q1   | 0.036    |
| loss_q2   | 0.0319   |
| loss_q3   | 0.03     |
| mse       | 0.0372   |
| mse_q0    | 0.066    |
| mse_q1    | 0.036    |
| mse_q2    | 0.0319   |
| mse_q3    | 0.03     |
| samples   | 211      |
| step      | 210      |
------------------------
------------------------
| grad_norm | 0.539    |
| loss      | 0.0462   |
| loss_q0   | 0.0829   |
| loss_q1   | 0.0385   |
| loss_q2   | 0.0279   |
| loss_q3   | 0.027    |
| mse       | 0.0462   |
| mse_q0    | 0.0829   |
| mse_q1    | 0.0385   |
| mse_q2    | 0.0279   |
| mse_q3    | 0.027    |
| samples   | 221      |
| step      | 220      |
------------------------
------------------------
| grad_norm | 0.483    |
| loss      | 0.0465   |
| loss_q0   | 0.0748   |
| loss_q1   | 0.0289   |
| loss_q2   | 0.0282   |
| loss_q3   | 0.026    |
| mse       | 0.0465   |
| mse_q0    | 0.0748   |
| mse_q1    | 0.0289   |
| mse_q2    | 0.0282   |
| mse_q3    | 0.026    |
| samples   | 231      |
| step      | 230      |
------------------------
