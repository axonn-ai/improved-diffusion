Logging to /tmp/openai-2024-01-05-12-37-27-100633
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 0        |
| loss      | 1.54e+05 |
| loss_q0   | 1.53e+05 |
| loss_q1   | 1.53e+05 |
| loss_q2   | 1.53e+05 |
| loss_q3   | 1.56e+05 |
| mse       | 1.53e+05 |
| mse_q0    | 1.53e+05 |
| mse_q1    | 1.53e+05 |
| mse_q2    | 1.53e+05 |
| mse_q3    | 1.53e+05 |
| samples   | 128      |
| step      | 0        |
| vb        | 1.57e+03 |
| vb_q0     | 657      |
| vb_q1     | 575      |
| vb_q2     | 690      |
| vb_q3     | 3.78e+03 |
------------------------
------------------------
| grad_norm | 164      |
| loss      | 1.53e+05 |
| loss_q0   | 1.53e+05 |
| loss_q1   | 1.52e+05 |
| loss_q2   | 1.53e+05 |
| loss_q3   | 1.56e+05 |
| mse       | 1.52e+05 |
| mse_q0    | 1.52e+05 |
| mse_q1    | 1.52e+05 |
| mse_q2    | 1.52e+05 |
| mse_q3    | 1.52e+05 |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 1.44e+03 |
| vb_q0     | 630      |
| vb_q1     | 581      |
| vb_q2     | 693      |
| vb_q3     | 3.98e+03 |
------------------------
------------------------
| grad_norm | 35       |
| loss      | 1.52e+05 |
| loss_q0   | 1.51e+05 |
| loss_q1   | 1.51e+05 |
| loss_q2   | 1.51e+05 |
| loss_q3   | 1.56e+05 |
| mse       | 1.51e+05 |
| mse_q0    | 1.51e+05 |
| mse_q1    | 1.51e+05 |
| mse_q2    | 1.51e+05 |
| mse_q3    | 1.51e+05 |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 1.66e+03 |
| vb_q0     | 618      |
| vb_q1     | 576      |
| vb_q2     | 687      |
| vb_q3     | 5.47e+03 |
------------------------
------------------------
| grad_norm | 32.1     |
| loss      | 8.25e+05 |
| loss_q0   | 1.5e+05  |
| loss_q1   | 1.5e+05  |
| loss_q2   | 1.5e+05  |
| loss_q3   | 3.07e+06 |
| mse       | 1.49e+05 |
| mse_q0    | 1.49e+05 |
| mse_q1    | 1.49e+05 |
| mse_q2    | 1.49e+05 |
| mse_q3    | 1.49e+05 |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 6.76e+05 |
| vb_q0     | 593      |
| vb_q1     | 570      |
| vb_q2     | 688      |
| vb_q3     | 2.92e+06 |
------------------------
------------------------
| grad_norm | 66.1     |
| loss      | 1.53e+05 |
| loss_q0   | 1.49e+05 |
| loss_q1   | 1.49e+05 |
| loss_q2   | 1.49e+05 |
| loss_q3   | 1.63e+05 |
| mse       | 1.48e+05 |
| mse_q0    | 1.48e+05 |
| mse_q1    | 1.48e+05 |
| mse_q2    | 1.48e+05 |
| mse_q3    | 1.48e+05 |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 4.47e+03 |
| vb_q0     | 617      |
| vb_q1     | 567      |
| vb_q2     | 665      |
| vb_q3     | 1.53e+04 |
------------------------
------------------------
| grad_norm | 78.5     |
| loss      | 1.49e+05 |
| loss_q0   | 1.48e+05 |
| loss_q1   | 1.48e+05 |
| loss_q2   | 1.48e+05 |
| loss_q3   | 1.54e+05 |
| mse       | 1.47e+05 |
| mse_q0    | 1.47e+05 |
| mse_q1    | 1.47e+05 |
| mse_q2    | 1.47e+05 |
| mse_q3    | 1.47e+05 |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 2.13e+03 |
| vb_q0     | 579      |
| vb_q1     | 563      |
| vb_q2     | 666      |
| vb_q3     | 6.98e+03 |
------------------------
------------------------
| grad_norm | 62.8     |
| loss      | 1.48e+05 |
| loss_q0   | 1.47e+05 |
| loss_q1   | 1.47e+05 |
| loss_q2   | 1.47e+05 |
| loss_q3   | 1.5e+05  |
| mse       | 1.46e+05 |
| mse_q0    | 1.46e+05 |
| mse_q1    | 1.46e+05 |
| mse_q2    | 1.46e+05 |
| mse_q3    | 1.46e+05 |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 1.44e+03 |
| vb_q0     | 599      |
| vb_q1     | 561      |
| vb_q2     | 653      |
| vb_q3     | 4.06e+03 |
------------------------
------------------------
| grad_norm | 43.2     |
| loss      | 1.49e+05 |
| loss_q0   | 1.46e+05 |
| loss_q1   | 1.46e+05 |
| loss_q2   | 1.46e+05 |
| loss_q3   | 1.57e+05 |
| mse       | 1.45e+05 |
| mse_q0    | 1.45e+05 |
| mse_q1    | 1.45e+05 |
| mse_q2    | 1.45e+05 |
| mse_q3    | 1.45e+05 |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 3.37e+03 |
| vb_q0     | 599      |
| vb_q1     | 557      |
| vb_q2     | 656      |
| vb_q3     | 1.17e+04 |
------------------------
------------------------
| grad_norm | 56.8     |
| loss      | 1.48e+05 |
| loss_q0   | 1.45e+05 |
| loss_q1   | 1.45e+05 |
| loss_q2   | 1.45e+05 |
| loss_q3   | 1.56e+05 |
| mse       | 1.44e+05 |
| mse_q0    | 1.44e+05 |
| mse_q1    | 1.44e+05 |
| mse_q2    | 1.44e+05 |
| mse_q3    | 1.44e+05 |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 3.38e+03 |
| vb_q0     | 590      |
| vb_q1     | 553      |
| vb_q2     | 645      |
| vb_q3     | 1.17e+04 |
------------------------
------------------------
| grad_norm | 39.1     |
| loss      | 7.91e+05 |
| loss_q0   | 1.44e+05 |
| loss_q1   | 1.44e+05 |
| loss_q2   | 1.44e+05 |
| loss_q3   | 2.82e+06 |
| mse       | 1.44e+05 |
| mse_q0    | 1.44e+05 |
| mse_q1    | 1.43e+05 |
| mse_q2    | 1.43e+05 |
| mse_q3    | 1.44e+05 |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 6.48e+05 |
| vb_q0     | 578      |
| vb_q1     | 548      |
| vb_q2     | 648      |
| vb_q3     | 2.67e+06 |
------------------------
------------------------
| grad_norm | 27.1     |
| loss      | 1.46e+05 |
| loss_q0   | 1.43e+05 |
| loss_q1   | 1.43e+05 |
| loss_q2   | 1.43e+05 |
| loss_q3   | 1.53e+05 |
| mse       | 1.43e+05 |
| mse_q0    | 1.43e+05 |
| mse_q1    | 1.43e+05 |
| mse_q2    | 1.43e+05 |
| mse_q3    | 1.43e+05 |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 2.91e+03 |
| vb_q0     | 565      |
| vb_q1     | 547      |
| vb_q2     | 647      |
| vb_q3     | 1.01e+04 |
------------------------
------------------------
| grad_norm | 17.6     |
| loss      | 1.44e+05 |
| loss_q0   | 1.43e+05 |
| loss_q1   | 1.43e+05 |
| loss_q2   | 1.43e+05 |
| loss_q3   | 1.47e+05 |
| mse       | 1.42e+05 |
| mse_q0    | 1.42e+05 |
| mse_q1    | 1.42e+05 |
| mse_q2    | 1.42e+05 |
| mse_q3    | 1.42e+05 |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 1.63e+03 |
| vb_q0     | 580      |
| vb_q1     | 544      |
| vb_q2     | 648      |
| vb_q3     | 5.21e+03 |
------------------------
------------------------
| grad_norm | 13.6     |
| loss      | 1.44e+05 |
| loss_q0   | 1.42e+05 |
| loss_q1   | 1.42e+05 |
| loss_q2   | 1.42e+05 |
| loss_q3   | 1.49e+05 |
| mse       | 1.42e+05 |
| mse_q0    | 1.42e+05 |
| mse_q1    | 1.42e+05 |
| mse_q2    | 1.42e+05 |
| mse_q3    | 1.42e+05 |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 2.45e+03 |
| vb_q0     | 596      |
| vb_q1     | 543      |
| vb_q2     | 638      |
| vb_q3     | 7.23e+03 |
------------------------
------------------------
| grad_norm | 10.6     |
| loss      | 1.43e+05 |
| loss_q0   | 1.42e+05 |
| loss_q1   | 1.42e+05 |
| loss_q2   | 1.42e+05 |
| loss_q3   | 1.45e+05 |
| mse       | 1.41e+05 |
| mse_q0    | 1.41e+05 |
| mse_q1    | 1.41e+05 |
| mse_q2    | 1.41e+05 |
| mse_q3    | 1.41e+05 |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 1.53e+03 |
| vb_q0     | 586      |
| vb_q1     | 541      |
| vb_q2     | 641      |
| vb_q3     | 4.37e+03 |
------------------------
------------------------
| grad_norm | 6.83     |
| loss      | 1.44e+05 |
| loss_q0   | 1.41e+05 |
| loss_q1   | 1.41e+05 |
| loss_q2   | 1.41e+05 |
| loss_q3   | 1.51e+05 |
| mse       | 1.41e+05 |
| mse_q0    | 1.41e+05 |
| mse_q1    | 1.41e+05 |
| mse_q2    | 1.41e+05 |
| mse_q3    | 1.41e+05 |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 2.95e+03 |
| vb_q0     | 547      |
| vb_q1     | 539      |
| vb_q2     | 641      |
| vb_q3     | 1.02e+04 |
------------------------
------------------------
| grad_norm | 5.32     |
| loss      | 1.44e+05 |
| loss_q0   | 1.41e+05 |
| loss_q1   | 1.41e+05 |
| loss_q2   | 1.41e+05 |
| loss_q3   | 1.53e+05 |
| mse       | 1.4e+05  |
| mse_q0    | 1.4e+05  |
| mse_q1    | 1.4e+05  |
| mse_q2    | 1.4e+05  |
| mse_q3    | 1.4e+05  |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 3.83e+03 |
| vb_q0     | 558      |
| vb_q1     | 536      |
| vb_q2     | 639      |
| vb_q3     | 1.3e+04  |
------------------------
------------------------
| grad_norm | 4.9      |
| loss      | 1.41e+05 |
| loss_q0   | 1.4e+05  |
| loss_q1   | 1.4e+05  |
| loss_q2   | 1.41e+05 |
| loss_q3   | 1.44e+05 |
| mse       | 1.4e+05  |
| mse_q0    | 1.4e+05  |
| mse_q1    | 1.4e+05  |
| mse_q2    | 1.4e+05  |
| mse_q3    | 1.4e+05  |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 1.43e+03 |
| vb_q0     | 567      |
| vb_q1     | 534      |
| vb_q2     | 627      |
| vb_q3     | 4.02e+03 |
------------------------
------------------------
| grad_norm | 4.33     |
| loss      | 1.41e+05 |
| loss_q0   | 1.4e+05  |
| loss_q1   | 1.4e+05  |
| loss_q2   | 1.4e+05  |
| loss_q3   | 1.45e+05 |
| mse       | 1.4e+05  |
| mse_q0    | 1.4e+05  |
| mse_q1    | 1.4e+05  |
| mse_q2    | 1.4e+05  |
| mse_q3    | 1.4e+05  |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 1.64e+03 |
| vb_q0     | 551      |
| vb_q1     | 535      |
| vb_q2     | 633      |
| vb_q3     | 4.88e+03 |
------------------------
------------------------
| grad_norm | 3        |
| loss      | 7.7e+05  |
| loss_q0   | 1.4e+05  |
| loss_q1   | 1.4e+05  |
| loss_q2   | 1.4e+05  |
| loss_q3   | 2.67e+06 |
| mse       | 1.39e+05 |
| mse_q0    | 1.39e+05 |
| mse_q1    | 1.39e+05 |
| mse_q2    | 1.39e+05 |
| mse_q3    | 1.39e+05 |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 6.3e+05  |
| vb_q0     | 557      |
| vb_q1     | 536      |
| vb_q2     | 634      |
| vb_q3     | 2.53e+06 |
------------------------
------------------------
| grad_norm | 2.49     |
| loss      | 1.42e+05 |
| loss_q0   | 1.4e+05  |
| loss_q1   | 1.4e+05  |
| loss_q2   | 1.4e+05  |
| loss_q3   | 1.47e+05 |
| mse       | 1.39e+05 |
| mse_q0    | 1.39e+05 |
| mse_q1    | 1.39e+05 |
| mse_q2    | 1.39e+05 |
| mse_q3    | 1.39e+05 |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 2.2e+03  |
| vb_q0     | 548      |
| vb_q1     | 535      |
| vb_q2     | 627      |
| vb_q3     | 7.85e+03 |
------------------------
