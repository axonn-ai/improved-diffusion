Logging to /tmp/openai-2024-01-10-15-02-53-205708
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 4.92     |
| loss      | 1.04     |
| loss_q0   | 1.02     |
| loss_q1   | 1        |
| loss_q2   | 0.994    |
| loss_q3   | 1.13     |
| mse       | 0.999    |
| mse_q0    | 1        |
| mse_q1    | 1        |
| mse_q2    | 0.989    |
| mse_q3    | 1        |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0422   |
| vb_q0     | 0.0138   |
| vb_q1     | 0.00495  |
| vb_q2     | 0.00526  |
| vb_q3     | 0.131    |
------------------------
------------------------
| grad_norm | 4.52     |
| loss      | 0.89     |
| loss_q0   | 0.953    |
| loss_q1   | 0.874    |
| loss_q2   | 0.849    |
| loss_q3   | 0.882    |
| mse       | 0.875    |
| mse_q0    | 0.928    |
| mse_q1    | 0.87     |
| mse_q2    | 0.844    |
| mse_q3    | 0.854    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0149   |
| vb_q0     | 0.0245   |
| vb_q1     | 0.00439  |
| vb_q2     | 0.00422  |
| vb_q3     | 0.0276   |
------------------------
------------------------
| grad_norm | 4        |
| loss      | 0.669    |
| loss_q0   | 0.759    |
| loss_q1   | 0.627    |
| loss_q2   | 0.606    |
| loss_q3   | 0.681    |
| mse       | 0.641    |
| mse_q0    | 0.74     |
| mse_q1    | 0.624    |
| mse_q2    | 0.603    |
| mse_q3    | 0.597    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0286   |
| vb_q0     | 0.0189   |
| vb_q1     | 0.00312  |
| vb_q2     | 0.00302  |
| vb_q3     | 0.0838   |
------------------------
------------------------
| grad_norm | 3.16     |
| loss      | 0.473    |
| loss_q0   | 0.659    |
| loss_q1   | 0.417    |
| loss_q2   | 0.398    |
| loss_q3   | 0.399    |
| mse       | 0.452    |
| mse_q0    | 0.592    |
| mse_q1    | 0.415    |
| mse_q2    | 0.396    |
| mse_q3    | 0.391    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0211   |
| vb_q0     | 0.067    |
| vb_q1     | 0.00208  |
| vb_q2     | 0.002    |
| vb_q3     | 0.00854  |
------------------------
------------------------
| grad_norm | 2.4      |
| loss      | 0.31     |
| loss_q0   | 0.445    |
| loss_q1   | 0.273    |
| loss_q2   | 0.255    |
| loss_q3   | 0.257    |
| mse       | 0.303    |
| mse_q0    | 0.43     |
| mse_q1    | 0.272    |
| mse_q2    | 0.254    |
| mse_q3    | 0.247    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.00722  |
| vb_q0     | 0.0145   |
| vb_q1     | 0.00138  |
| vb_q2     | 0.00127  |
| vb_q3     | 0.0105   |
------------------------
------------------------
| grad_norm | 1.71     |
| loss      | 0.214    |
| loss_q0   | 0.368    |
| loss_q1   | 0.185    |
| loss_q2   | 0.163    |
| loss_q3   | 0.154    |
| mse       | 0.21     |
| mse_q0    | 0.355    |
| mse_q1    | 0.184    |
| mse_q2    | 0.162    |
| mse_q3    | 0.15     |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.00442  |
| vb_q0     | 0.0133   |
| vb_q1     | 0.000938 |
| vb_q2     | 0.000825 |
| vb_q3     | 0.0035   |
------------------------
------------------------
| grad_norm | 1.18     |
| loss      | 0.168    |
| loss_q0   | 0.323    |
| loss_q1   | 0.133    |
| loss_q2   | 0.106    |
| loss_q3   | 0.0988   |
| mse       | 0.164    |
| mse_q0    | 0.309    |
| mse_q1    | 0.132    |
| mse_q2    | 0.105    |
| mse_q3    | 0.0962   |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.00468  |
| vb_q0     | 0.014    |
| vb_q1     | 0.000663 |
| vb_q2     | 0.000525 |
| vb_q3     | 0.00267  |
------------------------
------------------------
| grad_norm | 0.901    |
| loss      | 0.144    |
| loss_q0   | 0.326    |
| loss_q1   | 0.105    |
| loss_q2   | 0.0771   |
| loss_q3   | 0.0652   |
| mse       | 0.139    |
| mse_q0    | 0.309    |
| mse_q1    | 0.105    |
| mse_q2    | 0.0767   |
| mse_q3    | 0.0635   |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.00474  |
| vb_q0     | 0.0167   |
| vb_q1     | 0.000532 |
| vb_q2     | 0.000388 |
| vb_q3     | 0.00171  |
------------------------
------------------------
| grad_norm | 0.725    |
| loss      | 0.138    |
| loss_q0   | 0.332    |
| loss_q1   | 0.0963   |
| loss_q2   | 0.0597   |
| loss_q3   | 0.0478   |
| mse       | 0.133    |
| mse_q0    | 0.317    |
| mse_q1    | 0.0958   |
| mse_q2    | 0.0594   |
| mse_q3    | 0.0456   |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00475  |
| vb_q0     | 0.0151   |
| vb_q1     | 0.000493 |
| vb_q2     | 0.000297 |
| vb_q3     | 0.00218  |
------------------------
------------------------
| grad_norm | 0.598    |
| loss      | 0.129    |
| loss_q0   | 0.307    |
| loss_q1   | 0.0843   |
| loss_q2   | 0.0512   |
| loss_q3   | 0.0387   |
| mse       | 0.12     |
| mse_q0    | 0.278    |
| mse_q1    | 0.0839   |
| mse_q2    | 0.0509   |
| mse_q3    | 0.0367   |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00906  |
| vb_q0     | 0.0292   |
| vb_q1     | 0.000426 |
| vb_q2     | 0.000256 |
| vb_q3     | 0.002    |
------------------------
------------------------
| grad_norm | 0.542    |
| loss      | 0.265    |
| loss_q0   | 0.315    |
| loss_q1   | 0.0854   |
| loss_q2   | 0.0475   |
| loss_q3   | 0.616    |
| mse       | 0.116    |
| mse_q0    | 0.283    |
| mse_q1    | 0.085    |
| mse_q2    | 0.0472   |
| mse_q3    | 0.0314   |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.148    |
| vb_q0     | 0.0318   |
| vb_q1     | 0.00043  |
| vb_q2     | 0.000236 |
| vb_q3     | 0.584    |
------------------------
------------------------
| grad_norm | 0.493    |
| loss      | 0.13     |
| loss_q0   | 0.329    |
| loss_q1   | 0.0792   |
| loss_q2   | 0.0449   |
| loss_q3   | 0.0294   |
| mse       | 0.121    |
| mse_q0    | 0.3      |
| mse_q1    | 0.0788   |
| mse_q2    | 0.0447   |
| mse_q3    | 0.0284   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.00889  |
| vb_q0     | 0.0297   |
| vb_q1     | 0.000404 |
| vb_q2     | 0.000224 |
| vb_q3     | 0.000961 |
------------------------
------------------------
| grad_norm | 0.361    |
| loss      | 0.122    |
| loss_q0   | 0.324    |
| loss_q1   | 0.0804   |
| loss_q2   | 0.0429   |
| loss_q3   | 0.0274   |
| mse       | 0.113    |
| mse_q0    | 0.29     |
| mse_q1    | 0.08     |
| mse_q2    | 0.0427   |
| mse_q3    | 0.0266   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.00908  |
| vb_q0     | 0.0335   |
| vb_q1     | 0.000411 |
| vb_q2     | 0.000212 |
| vb_q3     | 0.000759 |
------------------------
------------------------
| grad_norm | 0.267    |
| loss      | 0.101    |
| loss_q0   | 0.285    |
| loss_q1   | 0.0786   |
| loss_q2   | 0.0428   |
| loss_q3   | 0.0261   |
| mse       | 0.0972   |
| mse_q0    | 0.27     |
| mse_q1    | 0.0782   |
| mse_q2    | 0.0426   |
| mse_q3    | 0.0254   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.0037   |
| vb_q0     | 0.0152   |
| vb_q1     | 0.000403 |
| vb_q2     | 0.000211 |
| vb_q3     | 0.000708 |
------------------------
------------------------
| grad_norm | 0.291    |
| loss      | 0.11     |
| loss_q0   | 0.282    |
| loss_q1   | 0.0758   |
| loss_q2   | 0.0407   |
| loss_q3   | 0.0244   |
| mse       | 0.106    |
| mse_q0    | 0.268    |
| mse_q1    | 0.0754   |
| mse_q2    | 0.0405   |
| mse_q3    | 0.0237   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.00398  |
| vb_q0     | 0.0139   |
| vb_q1     | 0.000384 |
| vb_q2     | 0.000201 |
| vb_q3     | 0.000663 |
------------------------
------------------------
| grad_norm | 0.306    |
| loss      | 0.105    |
| loss_q0   | 0.286    |
| loss_q1   | 0.0776   |
| loss_q2   | 0.0398   |
| loss_q3   | 0.0244   |
| mse       | 0.102    |
| mse_q0    | 0.276    |
| mse_q1    | 0.0772   |
| mse_q2    | 0.0396   |
| mse_q3    | 0.023    |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.00299  |
| vb_q0     | 0.0104   |
| vb_q1     | 0.000396 |
| vb_q2     | 0.000198 |
| vb_q3     | 0.0014   |
------------------------
------------------------
| grad_norm | 0.407    |
| loss      | 0.109    |
| loss_q0   | 0.287    |
| loss_q1   | 0.0719   |
| loss_q2   | 0.0375   |
| loss_q3   | 0.0238   |
| mse       | 0.1      |
| mse_q0    | 0.257    |
| mse_q1    | 0.0715   |
| mse_q2    | 0.0373   |
| mse_q3    | 0.0226   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.00863  |
| vb_q0     | 0.0307   |
| vb_q1     | 0.000361 |
| vb_q2     | 0.000189 |
| vb_q3     | 0.00116  |
------------------------
------------------------
| grad_norm | 0.405    |
| loss      | 0.107    |
| loss_q0   | 0.277    |
| loss_q1   | 0.0744   |
| loss_q2   | 0.0387   |
| loss_q3   | 0.0228   |
| mse       | 0.1      |
| mse_q0    | 0.253    |
| mse_q1    | 0.074    |
| mse_q2    | 0.0385   |
| mse_q3    | 0.0217   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.0069   |
| vb_q0     | 0.0242   |
| vb_q1     | 0.000378 |
| vb_q2     | 0.00019  |
| vb_q3     | 0.00108  |
------------------------
------------------------
| grad_norm | 0.261    |
| loss      | 0.0968   |
| loss_q0   | 0.256    |
| loss_q1   | 0.0773   |
| loss_q2   | 0.0385   |
| loss_q3   | 0.022    |
| mse       | 0.0936   |
| mse_q0    | 0.244    |
| mse_q1    | 0.0769   |
| mse_q2    | 0.0384   |
| mse_q3    | 0.0212   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.00311  |
| vb_q0     | 0.0115   |
| vb_q1     | 0.000395 |
| vb_q2     | 0.000194 |
| vb_q3     | 0.000792 |
------------------------
------------------------
| grad_norm | 0.225    |
| loss      | 0.105    |
| loss_q0   | 0.285    |
| loss_q1   | 0.0716   |
| loss_q2   | 0.0367   |
| loss_q3   | 0.022    |
| mse       | 0.1      |
| mse_q0    | 0.266    |
| mse_q1    | 0.0712   |
| mse_q2    | 0.0365   |
| mse_q3    | 0.0214   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00517  |
| vb_q0     | 0.0194   |
| vb_q1     | 0.000362 |
| vb_q2     | 0.000186 |
| vb_q3     | 0.00052  |
------------------------
