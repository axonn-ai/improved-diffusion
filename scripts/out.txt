WORLD SIZE: 1
CUDA AVAILABLE: True
Logging to /tmp/openai-2024-01-25-16-18-16-595780
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 2.9      |
| loss      | 1.01     |
| loss_q0   | 1.01     |
| loss_q1   | 1        |
| loss_q2   | 1        |
| loss_q3   | 1.01     |
| mse       | 0.997    |
| mse_q0    | 0.997    |
| mse_q1    | 0.998    |
| mse_q2    | 0.996    |
| mse_q3    | 0.997    |
| samples   | 128      |
| step      | 0        |
| vb        | 0.0114   |
| vb_q0     | 0.018    |
| vb_q1     | 0.00505  |
| vb_q2     | 0.00507  |
| vb_q3     | 0.0178   |
------------------------
------------------------
| grad_norm | 2.98     |
| loss      | 3.15     |
| loss_q0   | 0.965    |
| loss_q1   | 0.912    |
| loss_q2   | 0.912    |
| loss_q3   | 10.5     |
| mse       | 0.912    |
| mse_q0    | 0.936    |
| mse_q1    | 0.907    |
| mse_q2    | 0.907    |
| mse_q3    | 0.895    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 2.24     |
| vb_q0     | 0.0288   |
| vb_q1     | 0.00454  |
| vb_q2     | 0.00457  |
| vb_q3     | 9.6      |
------------------------
------------------------
| grad_norm | 2.84     |
| loss      | 0.747    |
| loss_q0   | 0.808    |
| loss_q1   | 0.726    |
| loss_q2   | 0.721    |
| loss_q3   | 0.733    |
| mse       | 0.735    |
| mse_q0    | 0.786    |
| mse_q1    | 0.723    |
| mse_q2    | 0.717    |
| mse_q3    | 0.714    |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0122   |
| vb_q0     | 0.0228   |
| vb_q1     | 0.00363  |
| vb_q2     | 0.0036   |
| vb_q3     | 0.0194   |
------------------------
------------------------
| grad_norm | 2.5      |
| loss      | 0.597    |
| loss_q0   | 0.67     |
| loss_q1   | 0.57     |
| loss_q2   | 0.555    |
| loss_q3   | 0.593    |
| mse       | 0.58     |
| mse_q0    | 0.644    |
| mse_q1    | 0.567    |
| mse_q2    | 0.552    |
| mse_q3    | 0.555    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0173   |
| vb_q0     | 0.0253   |
| vb_q1     | 0.00286  |
| vb_q2     | 0.0028   |
| vb_q3     | 0.0378   |
------------------------
------------------------
| grad_norm | 2.16     |
| loss      | 0.479    |
| loss_q0   | 0.604    |
| loss_q1   | 0.447    |
| loss_q2   | 0.429    |
| loss_q3   | 0.444    |
| mse       | 0.462    |
| mse_q0    | 0.55     |
| mse_q1    | 0.444    |
| mse_q2    | 0.427    |
| mse_q3    | 0.428    |
| samples   | 5.25e+03 |
| step      | 40       |
| vb        | 0.0178   |
| vb_q0     | 0.0536   |
| vb_q1     | 0.00226  |
| vb_q2     | 0.00216  |
| vb_q3     | 0.0156   |
------------------------
------------------------
| grad_norm | 1.87     |
| loss      | 0.382    |
| loss_q0   | 0.488    |
| loss_q1   | 0.35     |
| loss_q2   | 0.332    |
| loss_q3   | 0.344    |
| mse       | 0.368    |
| mse_q0    | 0.457    |
| mse_q1    | 0.348    |
| mse_q2    | 0.33     |
| mse_q3    | 0.324    |
| samples   | 6.53e+03 |
| step      | 50       |
| vb        | 0.014    |
| vb_q0     | 0.0305   |
| vb_q1     | 0.00175  |
| vb_q2     | 0.00167  |
| vb_q3     | 0.0199   |
------------------------
------------------------
| grad_norm | 1.61     |
| loss      | 0.302    |
| loss_q0   | 0.434    |
| loss_q1   | 0.278    |
| loss_q2   | 0.257    |
| loss_q3   | 0.255    |
| mse       | 0.293    |
| mse_q0    | 0.405    |
| mse_q1    | 0.277    |
| mse_q2    | 0.255    |
| mse_q3    | 0.249    |
| samples   | 7.81e+03 |
| step      | 60       |
| vb        | 0.0092   |
| vb_q0     | 0.0295   |
| vb_q1     | 0.0014   |
| vb_q2     | 0.00129  |
| vb_q3     | 0.0068   |
------------------------
------------------------
| grad_norm | 1.39     |
| loss      | 0.759    |
| loss_q0   | 0.385    |
| loss_q1   | 0.222    |
| loss_q2   | 0.2      |
| loss_q3   | 2.4      |
| mse       | 0.241    |
| mse_q0    | 0.355    |
| mse_q1    | 0.221    |
| mse_q2    | 0.199    |
| mse_q3    | 0.192    |
| samples   | 9.09e+03 |
| step      | 70       |
| vb        | 0.518    |
| vb_q0     | 0.0298   |
| vb_q1     | 0.00111  |
| vb_q2     | 0.00101  |
| vb_q3     | 2.21     |
------------------------
------------------------
| grad_norm | 1.19     |
| loss      | 0.213    |
| loss_q0   | 0.36     |
| loss_q1   | 0.184    |
| loss_q2   | 0.159    |
| loss_q3   | 0.154    |
| mse       | 0.204    |
| mse_q0    | 0.327    |
| mse_q1    | 0.183    |
| mse_q2    | 0.158    |
| mse_q3    | 0.149    |
| samples   | 1.04e+04 |
| step      | 80       |
| vb        | 0.00962  |
| vb_q0     | 0.0328   |
| vb_q1     | 0.000926 |
| vb_q2     | 0.000798 |
| vb_q3     | 0.00477  |
------------------------
------------------------
| grad_norm | 1.03     |
| loss      | 0.182    |
| loss_q0   | 0.327    |
| loss_q1   | 0.156    |
| loss_q2   | 0.128    |
| loss_q3   | 0.123    |
| mse       | 0.175    |
| mse_q0    | 0.304    |
| mse_q1    | 0.156    |
| mse_q2    | 0.127    |
| mse_q3    | 0.117    |
| samples   | 1.16e+04 |
| step      | 90       |
| vb        | 0.00748  |
| vb_q0     | 0.0226   |
| vb_q1     | 0.000791 |
| vb_q2     | 0.000645 |
| vb_q3     | 0.0064   |
------------------------
------------------------
| grad_norm | 0.917    |
| loss      | 0.158    |
| loss_q0   | 0.294    |
| loss_q1   | 0.134    |
| loss_q2   | 0.106    |
| loss_q3   | 0.0977   |
| mse       | 0.154    |
| mse_q0    | 0.282    |
| mse_q1    | 0.133    |
| mse_q2    | 0.105    |
| mse_q3    | 0.0938   |
| samples   | 1.29e+04 |
| step      | 100      |
| vb        | 0.00422  |
| vb_q0     | 0.0118   |
| vb_q1     | 0.000677 |
| vb_q2     | 0.000533 |
| vb_q3     | 0.00382  |
------------------------
------------------------
| grad_norm | 0.811    |
| loss      | 0.614    |
| loss_q0   | 0.296    |
| loss_q1   | 0.119    |
| loss_q2   | 0.0909   |
| loss_q3   | 2.03     |
| mse       | 0.138    |
| mse_q0    | 0.28     |
| mse_q1    | 0.118    |
| mse_q2    | 0.0904   |
| mse_q3    | 0.0777   |
| samples   | 1.42e+04 |
| step      | 110      |
| vb        | 0.476    |
| vb_q0     | 0.0159   |
| vb_q1     | 0.000596 |
| vb_q2     | 0.000456 |
| vb_q3     | 1.95     |
------------------------
------------------------
| grad_norm | 0.715    |
| loss      | 0.136    |
| loss_q0   | 0.283    |
| loss_q1   | 0.108    |
| loss_q2   | 0.0797   |
| loss_q3   | 0.068    |
| mse       | 0.13     |
| mse_q0    | 0.266    |
| mse_q1    | 0.108    |
| mse_q2    | 0.0793   |
| mse_q3    | 0.0654   |
| samples   | 1.55e+04 |
| step      | 120      |
| vb        | 0.0053   |
| vb_q0     | 0.0173   |
| vb_q1     | 0.000548 |
| vb_q2     | 0.000397 |
| vb_q3     | 0.00261  |
------------------------
------------------------
| grad_norm | 0.659    |
| loss      | 0.13     |
| loss_q0   | 0.288    |
| loss_q1   | 0.101    |
| loss_q2   | 0.0711   |
| loss_q3   | 0.0594   |
| mse       | 0.123    |
| mse_q0    | 0.263    |
| mse_q1    | 0.1      |
| mse_q2    | 0.0707   |
| mse_q3    | 0.0568   |
| samples   | 1.68e+04 |
| step      | 130      |
| vb        | 0.00704  |
| vb_q0     | 0.0243   |
| vb_q1     | 0.000509 |
| vb_q2     | 0.000356 |
| vb_q3     | 0.00268  |
------------------------
------------------------
| grad_norm | 0.636    |
| loss      | 0.124    |
| loss_q0   | 0.255    |
| loss_q1   | 0.0948   |
| loss_q2   | 0.0633   |
| loss_q3   | 0.0518   |
| mse       | 0.12     |
| mse_q0    | 0.244    |
| mse_q1    | 0.0943   |
| mse_q2    | 0.063    |
| mse_q3    | 0.0505   |
| samples   | 1.8e+04  |
| step      | 140      |
| vb        | 0.00387  |
| vb_q0     | 0.0116   |
| vb_q1     | 0.000478 |
| vb_q2     | 0.000318 |
| vb_q3     | 0.00129  |
------------------------
------------------------
| grad_norm | 0.566    |
| loss      | 0.116    |
| loss_q0   | 0.262    |
| loss_q1   | 0.0893   |
| loss_q2   | 0.059    |
| loss_q3   | 0.0475   |
| mse       | 0.11     |
| mse_q0    | 0.242    |
| mse_q1    | 0.0888   |
| mse_q2    | 0.0587   |
| mse_q3    | 0.0449   |
| samples   | 1.93e+04 |
| step      | 150      |
| vb        | 0.00588  |
| vb_q0     | 0.0197   |
| vb_q1     | 0.000455 |
| vb_q2     | 0.000297 |
| vb_q3     | 0.00257  |
------------------------
------------------------
| grad_norm | 0.528    |
| loss      | 0.107    |
| loss_q0   | 0.257    |
| loss_q1   | 0.0846   |
| loss_q2   | 0.056    |
| loss_q3   | 0.0426   |
| mse       | 0.102    |
| mse_q0    | 0.24     |
| mse_q1    | 0.0842   |
| mse_q2    | 0.0557   |
| mse_q3    | 0.0411   |
| samples   | 2.06e+04 |
| step      | 160      |
| vb        | 0.00447  |
| vb_q0     | 0.0165   |
| vb_q1     | 0.000427 |
| vb_q2     | 0.000278 |
| vb_q3     | 0.0015   |
------------------------
------------------------
| grad_norm | 0.496    |
| loss      | 0.198    |
| loss_q0   | 0.245    |
| loss_q1   | 0.0833   |
| loss_q2   | 0.0525   |
| loss_q3   | 0.411    |
| mse       | 0.1      |
| mse_q0    | 0.23     |
| mse_q1    | 0.0828   |
| mse_q2    | 0.0522   |
| mse_q3    | 0.0388   |
| samples   | 2.19e+04 |
| step      | 170      |
| vb        | 0.0974   |
| vb_q0     | 0.0158   |
| vb_q1     | 0.000427 |
| vb_q2     | 0.000263 |
| vb_q3     | 0.372    |
------------------------
------------------------
| grad_norm | 0.471    |
| loss      | 0.174    |
| loss_q0   | 0.232    |
| loss_q1   | 0.0793   |
| loss_q2   | 0.0514   |
| loss_q3   | 0.353    |
| mse       | 0.0953   |
| mse_q0    | 0.22     |
| mse_q1    | 0.0789   |
| mse_q2    | 0.0512   |
| mse_q3    | 0.0365   |
| samples   | 2.32e+04 |
| step      | 180      |
| vb        | 0.0791   |
| vb_q0     | 0.0115   |
| vb_q1     | 0.000401 |
| vb_q2     | 0.000256 |
| vb_q3     | 0.316    |
------------------------
------------------------
| grad_norm | 0.469    |
| loss      | 0.106    |
| loss_q0   | 0.261    |
| loss_q1   | 0.0796   |
| loss_q2   | 0.0495   |
| loss_q3   | 0.0363   |
| mse       | 0.101    |
| mse_q0    | 0.243    |
| mse_q1    | 0.0792   |
| mse_q2    | 0.0493   |
| mse_q3    | 0.0353   |
| samples   | 2.44e+04 |
| step      | 190      |
| vb        | 0.00503  |
| vb_q0     | 0.0184   |
| vb_q1     | 0.000402 |
| vb_q2     | 0.000247 |
| vb_q3     | 0.00106  |
------------------------
